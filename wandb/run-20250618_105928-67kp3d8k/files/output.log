Epoch 1/160: 84it [00:10,  8.24it/s]                        
2025-06-18 10:59:40.608 | INFO     | model:train:239 - [epoch 1]: epoch loss = 2.450380,   acc = 0.159344
[epoch 1]: epoch loss = 2.450380,   acc = 0.159344
Epoch 2/160: 84it [00:09,  8.84it/s]                        
2025-06-18 10:59:50.171 | INFO     | model:train:239 - [epoch 2]: epoch loss = 2.349349,   acc = 0.173792
[epoch 2]: epoch loss = 2.349349,   acc = 0.173792
Epoch 3/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:00:00.033 | INFO     | model:train:239 - [epoch 3]: epoch loss = 2.283830,   acc = 0.181229
[epoch 3]: epoch loss = 2.283830,   acc = 0.181229
Epoch 4/160: 84it [00:09,  8.66it/s]                        
2025-06-18 11:00:11.033 | INFO     | model:train:239 - [epoch 4]: epoch loss = 2.157906,   acc = 0.192207
[epoch 4]: epoch loss = 2.157906,   acc = 0.192207
Epoch 5/160: 84it [00:09,  8.62it/s]                        
2025-06-18 11:00:20.872 | INFO     | model:train:239 - [epoch 5]: epoch loss = 2.081724,   acc = 0.245417
[epoch 5]: epoch loss = 2.081724,   acc = 0.245417
Epoch 6/160: 84it [00:09,  8.65it/s]                        
2025-06-18 11:00:30.652 | INFO     | model:train:239 - [epoch 6]: epoch loss = 1.903708,   acc = 0.290898
[epoch 6]: epoch loss = 1.903708,   acc = 0.290898
Epoch 7/160: 84it [00:09,  8.55it/s]                        
2025-06-18 11:00:40.579 | INFO     | model:train:239 - [epoch 7]: epoch loss = 1.730956,   acc = 0.387635
[epoch 7]: epoch loss = 1.730956,   acc = 0.387635
Epoch 8/160: 84it [00:10,  8.35it/s]                        
2025-06-18 11:00:50.727 | INFO     | model:train:239 - [epoch 8]: epoch loss = 1.631461,   acc = 0.464159
[epoch 8]: epoch loss = 1.631461,   acc = 0.464159
Epoch 9/160: 84it [00:09,  8.57it/s]                        
2025-06-18 11:01:00.671 | INFO     | model:train:239 - [epoch 9]: epoch loss = 1.516783,   acc = 0.527098
[epoch 9]: epoch loss = 1.516783,   acc = 0.527098
Epoch 10/160: 84it [00:09,  8.51it/s]                        
2025-06-18 11:01:10.679 | INFO     | model:train:239 - [epoch 10]: epoch loss = 1.416746,   acc = 0.574424
[epoch 10]: epoch loss = 1.416746,   acc = 0.574424
Epoch 11/160: 84it [00:10,  8.35it/s]                        
2025-06-18 11:01:20.849 | INFO     | model:train:239 - [epoch 11]: epoch loss = 1.379962,   acc = 0.587706
[epoch 11]: epoch loss = 1.379962,   acc = 0.587706
Epoch 12/160: 84it [00:10,  8.37it/s]                        
2025-06-18 11:01:30.950 | INFO     | model:train:239 - [epoch 12]: epoch loss = 1.306338,   acc = 0.618349
[epoch 12]: epoch loss = 1.306338,   acc = 0.618349
Epoch 13/160: 84it [00:09,  8.52it/s]                        
2025-06-18 11:01:40.938 | INFO     | model:train:239 - [epoch 13]: epoch loss = 1.217279,   acc = 0.643146
[epoch 13]: epoch loss = 1.217279,   acc = 0.643146
Epoch 14/160: 84it [00:09,  8.76it/s]                        
2025-06-18 11:01:50.670 | INFO     | model:train:239 - [epoch 14]: epoch loss = 1.179677,   acc = 0.663066
[epoch 14]: epoch loss = 1.179677,   acc = 0.663066
Epoch 15/160: 84it [00:09,  8.51it/s]                        
2025-06-18 11:02:00.648 | INFO     | model:train:239 - [epoch 15]: epoch loss = 1.211083,   acc = 0.654792
[epoch 15]: epoch loss = 1.211083,   acc = 0.654792
Epoch 16/160: 84it [00:09,  8.41it/s]                        
2025-06-18 11:02:10.721 | INFO     | model:train:239 - [epoch 16]: epoch loss = 1.132975,   acc = 0.677119
[epoch 16]: epoch loss = 1.132975,   acc = 0.677119
Epoch 17/160: 84it [00:09,  8.57it/s]                        
2025-06-18 11:02:20.663 | INFO     | model:train:239 - [epoch 17]: epoch loss = 1.066487,   acc = 0.706392
[epoch 17]: epoch loss = 1.066487,   acc = 0.706392
Epoch 18/160: 84it [00:09,  8.44it/s]                        
2025-06-18 11:02:30.691 | INFO     | model:train:239 - [epoch 18]: epoch loss = 1.051184,   acc = 0.710665
[epoch 18]: epoch loss = 1.051184,   acc = 0.710665
Epoch 19/160: 84it [00:09,  8.53it/s]                        
2025-06-18 11:02:40.836 | INFO     | model:train:239 - [epoch 19]: epoch loss = 0.991771,   acc = 0.732128
[epoch 19]: epoch loss = 0.991771,   acc = 0.732128
Epoch 20/160: 84it [00:09,  8.60it/s]                        
2025-06-18 11:02:50.686 | INFO     | model:train:239 - [epoch 20]: epoch loss = 0.976923,   acc = 0.743544
[epoch 20]: epoch loss = 0.976923,   acc = 0.743544
/home/djh/my_envs/dai_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2776: UserWarning: y_pred contains classes not in y_true
  warnings.warn("y_pred contains classes not in y_true")
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([17027,  4381,  7333,  7876, 16104, 14190,  1890, 11481,  1254,
        2277,  1388,  4771]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), array([35417,  5127,  3970,  4731,  9297, 12040,  4973,  7258,  1532,
        1652,  3975]))
2025-06-18 11:02:51.137 | INFO     | model:train:255 - [epoch 20]: val loss = 2.982152,   val acc = 0.446450,   val balanced acc = 0.467310
[epoch 20]: val loss = 2.982152,   val acc = 0.446450,   val balanced acc = 0.467310
Epoch 21/160:  83%|████████▎ | 68/82 [00:08<00:01,  8.75it/s]wandb: WARNING Tried to log to step 20 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 21/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:03:01.068 | INFO     | model:train:239 - [epoch 21]: epoch loss = 0.944501,   acc = 0.757144
[epoch 21]: epoch loss = 0.944501,   acc = 0.757144
Epoch 22/160: 84it [00:09,  8.67it/s]                        
2025-06-18 11:03:10.839 | INFO     | model:train:239 - [epoch 22]: epoch loss = 0.901938,   acc = 0.767215
[epoch 22]: epoch loss = 0.901938,   acc = 0.767215
Epoch 23/160: 84it [00:09,  8.78it/s]                        
2025-06-18 11:03:20.484 | INFO     | model:train:239 - [epoch 23]: epoch loss = 0.888152,   acc = 0.773318
[epoch 23]: epoch loss = 0.888152,   acc = 0.773318
Epoch 24/160: 84it [00:09,  8.81it/s]                        
2025-06-18 11:03:30.110 | INFO     | model:train:239 - [epoch 24]: epoch loss = 0.859756,   acc = 0.781833
[epoch 24]: epoch loss = 0.859756,   acc = 0.781833
Epoch 25/160: 84it [00:09,  8.57it/s]                        
2025-06-18 11:03:39.994 | INFO     | model:train:239 - [epoch 25]: epoch loss = 0.835985,   acc = 0.790394
[epoch 25]: epoch loss = 0.835985,   acc = 0.790394
Epoch 26/160: 84it [00:09,  8.44it/s]                        
2025-06-18 11:03:50.116 | INFO     | model:train:239 - [epoch 26]: epoch loss = 0.811947,   acc = 0.798048
[epoch 26]: epoch loss = 0.811947,   acc = 0.798048
Epoch 27/160: 84it [00:09,  8.44it/s]                        
2025-06-18 11:04:00.134 | INFO     | model:train:239 - [epoch 27]: epoch loss = 0.830067,   acc = 0.791056
[epoch 27]: epoch loss = 0.830067,   acc = 0.791056
Epoch 28/160: 84it [00:09,  8.40it/s]                        
2025-06-18 11:04:10.205 | INFO     | model:train:239 - [epoch 28]: epoch loss = 0.816265,   acc = 0.797067
[epoch 28]: epoch loss = 0.816265,   acc = 0.797067
Epoch 29/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:04:20.214 | INFO     | model:train:239 - [epoch 29]: epoch loss = 0.777687,   acc = 0.809506
[epoch 29]: epoch loss = 0.777687,   acc = 0.809506
Epoch 30/160: 84it [00:09,  8.50it/s]                        
2025-06-18 11:04:30.185 | INFO     | model:train:239 - [epoch 30]: epoch loss = 0.743230,   acc = 0.821170
[epoch 30]: epoch loss = 0.743230,   acc = 0.821170
Epoch 31/160: 84it [00:09,  8.49it/s]                        
2025-06-18 11:04:40.159 | INFO     | model:train:239 - [epoch 31]: epoch loss = 0.719261,   acc = 0.830565
[epoch 31]: epoch loss = 0.719261,   acc = 0.830565
Epoch 32/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:04:50.005 | INFO     | model:train:239 - [epoch 32]: epoch loss = 0.754998,   acc = 0.821354
[epoch 32]: epoch loss = 0.754998,   acc = 0.821354
Epoch 33/160: 84it [00:09,  8.52it/s]                        
2025-06-18 11:04:59.945 | INFO     | model:train:239 - [epoch 33]: epoch loss = 0.704350,   acc = 0.832712
[epoch 33]: epoch loss = 0.704350,   acc = 0.832712
Epoch 34/160: 84it [00:09,  8.58it/s]                        
2025-06-18 11:05:09.816 | INFO     | model:train:239 - [epoch 34]: epoch loss = 0.669400,   acc = 0.845075
[epoch 34]: epoch loss = 0.669400,   acc = 0.845075
Epoch 35/160: 84it [00:09,  8.58it/s]                        
2025-06-18 11:05:19.687 | INFO     | model:train:239 - [epoch 35]: epoch loss = 0.657134,   acc = 0.848639
[epoch 35]: epoch loss = 0.657134,   acc = 0.848639
Epoch 36/160: 84it [00:09,  8.51it/s]                        
2025-06-18 11:05:29.628 | INFO     | model:train:239 - [epoch 36]: epoch loss = 0.636339,   acc = 0.854144
[epoch 36]: epoch loss = 0.636339,   acc = 0.854144
Epoch 37/160: 84it [00:09,  8.52it/s]                        
2025-06-18 11:05:39.562 | INFO     | model:train:239 - [epoch 37]: epoch loss = 0.615908,   acc = 0.861403
[epoch 37]: epoch loss = 0.615908,   acc = 0.861403
Epoch 38/160: 84it [00:09,  8.44it/s]                        
2025-06-18 11:05:49.599 | INFO     | model:train:239 - [epoch 38]: epoch loss = 0.600525,   acc = 0.867636
[epoch 38]: epoch loss = 0.600525,   acc = 0.867636
Epoch 39/160: 84it [00:09,  8.42it/s]                        
2025-06-18 11:05:59.653 | INFO     | model:train:239 - [epoch 39]: epoch loss = 0.598281,   acc = 0.870452
[epoch 39]: epoch loss = 0.598281,   acc = 0.870452
Epoch 40/160: 84it [00:09,  8.69it/s]                        
2025-06-18 11:06:09.404 | INFO     | model:train:239 - [epoch 40]: epoch loss = 0.584806,   acc = 0.873294
[epoch 40]: epoch loss = 0.584806,   acc = 0.873294
/home/djh/my_envs/dai_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2776: UserWarning: y_pred contains classes not in y_true
  warnings.warn("y_pred contains classes not in y_true")
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 8382,  6664,  8716,  8814, 13559, 16906,  7431,  9150,  2779,
        1366,  1982,  4223]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), array([35417,  5127,  3970,  4731,  9297, 12040,  4973,  7258,  1532,
        1652,  3975]))
2025-06-18 11:06:09.858 | INFO     | model:train:255 - [epoch 40]: val loss = 3.421898,   val acc = 0.418975,   val balanced acc = 0.508748
[epoch 40]: val loss = 3.421898,   val acc = 0.418975,   val balanced acc = 0.508748
Epoch 41/160:  98%|█████████▊| 80/82 [00:09<00:00,  7.82it/s]wandb: WARNING Tried to log to step 40 that is less than the current step 41. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 41/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:06:19.904 | INFO     | model:train:239 - [epoch 41]: epoch loss = 0.585388,   acc = 0.872310
[epoch 41]: epoch loss = 0.585388,   acc = 0.872310
Epoch 42/160: 84it [00:10,  8.36it/s]                        
2025-06-18 11:06:30.040 | INFO     | model:train:239 - [epoch 42]: epoch loss = 0.569343,   acc = 0.878472
[epoch 42]: epoch loss = 0.569343,   acc = 0.878472
Epoch 43/160: 84it [00:09,  8.65it/s]                        
2025-06-18 11:06:39.828 | INFO     | model:train:239 - [epoch 43]: epoch loss = 0.546836,   acc = 0.884476
[epoch 43]: epoch loss = 0.546836,   acc = 0.884476
Epoch 44/160: 84it [00:09,  8.51it/s]                        
2025-06-18 11:06:49.787 | INFO     | model:train:239 - [epoch 44]: epoch loss = 0.531519,   acc = 0.888706
[epoch 44]: epoch loss = 0.531519,   acc = 0.888706
Epoch 45/160: 84it [00:09,  8.50it/s]                        
2025-06-18 11:06:59.749 | INFO     | model:train:239 - [epoch 45]: epoch loss = 0.522586,   acc = 0.892411
[epoch 45]: epoch loss = 0.522586,   acc = 0.892411
Epoch 46/160: 84it [00:09,  8.62it/s]                        
2025-06-18 11:07:09.581 | INFO     | model:train:239 - [epoch 46]: epoch loss = 0.510020,   acc = 0.896026
[epoch 46]: epoch loss = 0.510020,   acc = 0.896026
Epoch 47/160: 84it [00:09,  8.41it/s]                        
2025-06-18 11:07:19.858 | INFO     | model:train:239 - [epoch 47]: epoch loss = 0.505707,   acc = 0.896735
[epoch 47]: epoch loss = 0.505707,   acc = 0.896735
Epoch 48/160: 84it [00:09,  8.53it/s]                        
2025-06-18 11:07:29.795 | INFO     | model:train:239 - [epoch 48]: epoch loss = 0.503994,   acc = 0.897888
[epoch 48]: epoch loss = 0.503994,   acc = 0.897888
Epoch 49/160: 84it [00:09,  8.42it/s]                        
2025-06-18 11:07:39.855 | INFO     | model:train:239 - [epoch 49]: epoch loss = 0.499139,   acc = 0.898965
[epoch 49]: epoch loss = 0.499139,   acc = 0.898965
Epoch 50/160: 84it [00:10,  8.36it/s]                        
2025-06-18 11:07:50.005 | INFO     | model:train:239 - [epoch 50]: epoch loss = 0.496933,   acc = 0.898273
[epoch 50]: epoch loss = 0.496933,   acc = 0.898273
Epoch 51/160: 84it [00:09,  8.58it/s]                        
2025-06-18 11:07:59.883 | INFO     | model:train:239 - [epoch 51]: epoch loss = 0.492443,   acc = 0.899538
[epoch 51]: epoch loss = 0.492443,   acc = 0.899538
Epoch 52/160: 84it [00:09,  8.92it/s]                        
2025-06-18 11:08:09.374 | INFO     | model:train:239 - [epoch 52]: epoch loss = 0.500237,   acc = 0.895449
[epoch 52]: epoch loss = 0.500237,   acc = 0.895449
Epoch 53/160: 84it [00:09,  8.56it/s]                        
2025-06-18 11:08:19.281 | INFO     | model:train:239 - [epoch 53]: epoch loss = 0.485935,   acc = 0.899447
[epoch 53]: epoch loss = 0.485935,   acc = 0.899447
Epoch 54/160: 84it [00:09,  8.64it/s]                        
2025-06-18 11:08:29.085 | INFO     | model:train:239 - [epoch 54]: epoch loss = 0.468040,   acc = 0.904685
[epoch 54]: epoch loss = 0.468040,   acc = 0.904685
Epoch 55/160: 84it [00:09,  8.72it/s]                        
2025-06-18 11:08:38.807 | INFO     | model:train:239 - [epoch 55]: epoch loss = 0.458584,   acc = 0.908421
[epoch 55]: epoch loss = 0.458584,   acc = 0.908421
Epoch 56/160: 84it [00:09,  8.81it/s]                        
2025-06-18 11:08:48.426 | INFO     | model:train:239 - [epoch 56]: epoch loss = 0.447973,   acc = 0.912131
[epoch 56]: epoch loss = 0.447973,   acc = 0.912131
Epoch 57/160: 84it [00:09,  8.44it/s]                        
2025-06-18 11:08:58.736 | INFO     | model:train:239 - [epoch 57]: epoch loss = 0.433096,   acc = 0.916595
[epoch 57]: epoch loss = 0.433096,   acc = 0.916595
Epoch 58/160: 84it [00:09,  8.49it/s]                        
2025-06-18 11:09:09.209 | INFO     | model:train:239 - [epoch 58]: epoch loss = 0.424257,   acc = 0.917978
[epoch 58]: epoch loss = 0.424257,   acc = 0.917978
Epoch 59/160: 84it [00:10,  8.38it/s]                        
2025-06-18 11:09:19.305 | INFO     | model:train:239 - [epoch 59]: epoch loss = 0.419093,   acc = 0.920225
[epoch 59]: epoch loss = 0.419093,   acc = 0.920225
Epoch 60/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:09:29.175 | INFO     | model:train:239 - [epoch 60]: epoch loss = 0.421814,   acc = 0.919103
[epoch 60]: epoch loss = 0.421814,   acc = 0.919103
/home/djh/my_envs/dai_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2776: UserWarning: y_pred contains classes not in y_true
  warnings.warn("y_pred contains classes not in y_true")
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([13585,  5666,  7031,  7521, 12413, 14584,  6756, 12931,   374,
        2551,  2613,  3947]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), array([35417,  5127,  3970,  4731,  9297, 12040,  4973,  7258,  1532,
        1652,  3975]))
2025-06-18 11:09:29.613 | INFO     | model:train:255 - [epoch 60]: val loss = 3.708739,   val acc = 0.439459,   val balanced acc = 0.497235
[epoch 60]: val loss = 3.708739,   val acc = 0.439459,   val balanced acc = 0.497235
2025-06-18 11:09:29.650 | INFO     | model:train:275 - EarlyStopping counter: 1 out of 3
EarlyStopping counter: 1 out of 3
Epoch 61/160:   0%|          | 0/82 [00:00<?, ?it/s]wandb: WARNING Tried to log to step 60 that is less than the current step 61. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 61/160: 84it [00:09,  8.68it/s]                        
2025-06-18 11:09:39.412 | INFO     | model:train:239 - [epoch 61]: epoch loss = 0.416785,   acc = 0.920320
[epoch 61]: epoch loss = 0.416785,   acc = 0.920320
Epoch 62/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:09:49.335 | INFO     | model:train:239 - [epoch 62]: epoch loss = 0.409703,   acc = 0.921392
[epoch 62]: epoch loss = 0.409703,   acc = 0.921392
Epoch 63/160: 84it [00:09,  8.54it/s]                        
2025-06-18 11:09:59.308 | INFO     | model:train:239 - [epoch 63]: epoch loss = 0.406058,   acc = 0.921510
[epoch 63]: epoch loss = 0.406058,   acc = 0.921510
Epoch 64/160: 84it [00:09,  8.62it/s]                        
2025-06-18 11:10:09.200 | INFO     | model:train:239 - [epoch 64]: epoch loss = 0.415495,   acc = 0.918863
[epoch 64]: epoch loss = 0.415495,   acc = 0.918863
Epoch 65/160: 84it [00:09,  8.41it/s]                        
2025-06-18 11:10:19.375 | INFO     | model:train:239 - [epoch 65]: epoch loss = 0.399066,   acc = 0.923183
[epoch 65]: epoch loss = 0.399066,   acc = 0.923183
Epoch 66/160: 84it [00:09,  8.76it/s]                        
2025-06-18 11:10:29.114 | INFO     | model:train:239 - [epoch 66]: epoch loss = 0.391885,   acc = 0.925259
[epoch 66]: epoch loss = 0.391885,   acc = 0.925259
Epoch 67/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:10:38.973 | INFO     | model:train:239 - [epoch 67]: epoch loss = 0.384087,   acc = 0.927587
[epoch 67]: epoch loss = 0.384087,   acc = 0.927587
Epoch 68/160: 84it [00:09,  8.85it/s]                        
2025-06-18 11:10:48.558 | INFO     | model:train:239 - [epoch 68]: epoch loss = 0.381970,   acc = 0.929606
[epoch 68]: epoch loss = 0.381970,   acc = 0.929606
Epoch 69/160: 84it [00:09,  8.71it/s]                        
2025-06-18 11:10:58.270 | INFO     | model:train:239 - [epoch 69]: epoch loss = 0.375004,   acc = 0.931659
[epoch 69]: epoch loss = 0.375004,   acc = 0.931659
Epoch 70/160: 84it [00:09,  8.73it/s]                        
2025-06-18 11:11:08.037 | INFO     | model:train:239 - [epoch 70]: epoch loss = 0.374446,   acc = 0.931517
[epoch 70]: epoch loss = 0.374446,   acc = 0.931517
Epoch 71/160: 84it [00:09,  8.42it/s]                        
2025-06-18 11:11:18.154 | INFO     | model:train:239 - [epoch 71]: epoch loss = 0.366463,   acc = 0.932807
[epoch 71]: epoch loss = 0.366463,   acc = 0.932807
Epoch 72/160: 84it [00:09,  8.56it/s]                        
2025-06-18 11:11:28.197 | INFO     | model:train:239 - [epoch 72]: epoch loss = 0.363475,   acc = 0.933309
[epoch 72]: epoch loss = 0.363475,   acc = 0.933309
Epoch 73/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:11:38.210 | INFO     | model:train:239 - [epoch 73]: epoch loss = 0.359411,   acc = 0.933134
[epoch 73]: epoch loss = 0.359411,   acc = 0.933134
Epoch 74/160: 84it [00:09,  8.56it/s]                        
2025-06-18 11:11:48.118 | INFO     | model:train:239 - [epoch 74]: epoch loss = 0.357996,   acc = 0.934967
[epoch 74]: epoch loss = 0.357996,   acc = 0.934967
Epoch 75/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:11:58.124 | INFO     | model:train:239 - [epoch 75]: epoch loss = 0.354379,   acc = 0.936220
[epoch 75]: epoch loss = 0.354379,   acc = 0.936220
Epoch 76/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:12:08.147 | INFO     | model:train:239 - [epoch 76]: epoch loss = 0.353467,   acc = 0.935822
[epoch 76]: epoch loss = 0.353467,   acc = 0.935822
Epoch 77/160: 84it [00:09,  8.57it/s]                        
2025-06-18 11:12:18.031 | INFO     | model:train:239 - [epoch 77]: epoch loss = 0.349134,   acc = 0.937395
[epoch 77]: epoch loss = 0.349134,   acc = 0.937395
Epoch 78/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:12:28.058 | INFO     | model:train:239 - [epoch 78]: epoch loss = 0.342709,   acc = 0.938844
[epoch 78]: epoch loss = 0.342709,   acc = 0.938844
Epoch 79/160: 84it [00:10,  8.38it/s]                        
2025-06-18 11:12:38.282 | INFO     | model:train:239 - [epoch 79]: epoch loss = 0.346752,   acc = 0.937189
[epoch 79]: epoch loss = 0.346752,   acc = 0.937189
Epoch 80/160: 84it [00:09,  8.45it/s]                        
2025-06-18 11:12:48.303 | INFO     | model:train:239 - [epoch 80]: epoch loss = 0.339710,   acc = 0.938196
[epoch 80]: epoch loss = 0.339710,   acc = 0.938196
/home/djh/my_envs/dai_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2776: UserWarning: y_pred contains classes not in y_true
  warnings.warn("y_pred contains classes not in y_true")
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([16761,  5958,  5789,  6634, 13014, 15102,  7064, 11699,   380,
        1655,  1909,  4007]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), array([35417,  5127,  3970,  4731,  9297, 12040,  4973,  7258,  1532,
        1652,  3975]))
2025-06-18 11:12:48.773 | INFO     | model:train:255 - [epoch 80]: val loss = 3.280974,   val acc = 0.457309,   val balanced acc = 0.501856
[epoch 80]: val loss = 3.280974,   val acc = 0.457309,   val balanced acc = 0.501856
2025-06-18 11:12:48.838 | INFO     | model:train:275 - EarlyStopping counter: 2 out of 3
EarlyStopping counter: 2 out of 3
Epoch 81/160:  10%|▉         | 8/82 [00:00<00:07,  9.50it/s]wandb: WARNING Tried to log to step 80 that is less than the current step 81. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 81/160: 84it [00:10,  8.35it/s]                        
2025-06-18 11:12:58.967 | INFO     | model:train:239 - [epoch 81]: epoch loss = 0.334253,   acc = 0.940317
[epoch 81]: epoch loss = 0.334253,   acc = 0.940317
Epoch 82/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:13:08.955 | INFO     | model:train:239 - [epoch 82]: epoch loss = 0.331948,   acc = 0.941423
[epoch 82]: epoch loss = 0.331948,   acc = 0.941423
Epoch 83/160: 84it [00:09,  8.55it/s]                        
2025-06-18 11:13:18.866 | INFO     | model:train:239 - [epoch 83]: epoch loss = 0.326975,   acc = 0.943206
[epoch 83]: epoch loss = 0.326975,   acc = 0.943206
Epoch 84/160: 84it [00:09,  8.57it/s]                        
2025-06-18 11:13:28.815 | INFO     | model:train:239 - [epoch 84]: epoch loss = 0.326672,   acc = 0.943134
[epoch 84]: epoch loss = 0.326672,   acc = 0.943134
Epoch 85/160: 84it [00:09,  8.46it/s]                        
2025-06-18 11:13:38.829 | INFO     | model:train:239 - [epoch 85]: epoch loss = 0.326964,   acc = 0.942627
[epoch 85]: epoch loss = 0.326964,   acc = 0.942627
Epoch 86/160: 84it [00:09,  8.48it/s]                        
2025-06-18 11:13:48.847 | INFO     | model:train:239 - [epoch 86]: epoch loss = 0.318005,   acc = 0.944293
[epoch 86]: epoch loss = 0.318005,   acc = 0.944293
Epoch 87/160: 84it [00:09,  8.51it/s]                        
2025-06-18 11:13:58.802 | INFO     | model:train:239 - [epoch 87]: epoch loss = 0.314527,   acc = 0.945615
[epoch 87]: epoch loss = 0.314527,   acc = 0.945615
Epoch 88/160: 84it [00:09,  8.67it/s]                        
2025-06-18 11:14:08.568 | INFO     | model:train:239 - [epoch 88]: epoch loss = 0.321392,   acc = 0.944687
[epoch 88]: epoch loss = 0.321392,   acc = 0.944687
Epoch 89/160: 84it [00:09,  8.47it/s]                        
2025-06-18 11:14:18.564 | INFO     | model:train:239 - [epoch 89]: epoch loss = 0.318300,   acc = 0.943290
[epoch 89]: epoch loss = 0.318300,   acc = 0.943290
Epoch 90/160: 84it [00:09,  8.52it/s]                        
2025-06-18 11:14:28.506 | INFO     | model:train:239 - [epoch 90]: epoch loss = 0.320456,   acc = 0.942816
[epoch 90]: epoch loss = 0.320456,   acc = 0.942816
Epoch 91/160: 84it [00:09,  8.51it/s]                        
2025-06-18 11:14:38.457 | INFO     | model:train:239 - [epoch 91]: epoch loss = 0.314859,   acc = 0.944081
[epoch 91]: epoch loss = 0.314859,   acc = 0.944081
Epoch 92/160: 84it [00:09,  8.59it/s]                        
2025-06-18 11:14:48.305 | INFO     | model:train:239 - [epoch 92]: epoch loss = 0.308024,   acc = 0.945991
[epoch 92]: epoch loss = 0.308024,   acc = 0.945991
Epoch 93/160: 84it [00:09,  8.45it/s]                        
2025-06-18 11:14:58.336 | INFO     | model:train:239 - [epoch 93]: epoch loss = 0.304086,   acc = 0.947888
[epoch 93]: epoch loss = 0.304086,   acc = 0.947888
Epoch 94/160: 84it [00:09,  8.55it/s]                        
2025-06-18 11:15:08.225 | INFO     | model:train:239 - [epoch 94]: epoch loss = 0.302194,   acc = 0.948622
[epoch 94]: epoch loss = 0.302194,   acc = 0.948622
Epoch 95/160: 84it [00:10,  8.36it/s]                        
2025-06-18 11:15:18.366 | INFO     | model:train:239 - [epoch 95]: epoch loss = 0.296682,   acc = 0.949325
[epoch 95]: epoch loss = 0.296682,   acc = 0.949325
Epoch 96/160: 84it [00:09,  8.65it/s]                        
2025-06-18 11:15:28.141 | INFO     | model:train:239 - [epoch 96]: epoch loss = 0.300597,   acc = 0.949831
[epoch 96]: epoch loss = 0.300597,   acc = 0.949831
Epoch 97/160: 84it [00:09,  8.50it/s]                        
2025-06-18 11:15:38.110 | INFO     | model:train:239 - [epoch 97]: epoch loss = 0.299827,   acc = 0.948332
[epoch 97]: epoch loss = 0.299827,   acc = 0.948332
Epoch 98/160: 84it [00:10,  8.40it/s]                        
2025-06-18 11:15:48.182 | INFO     | model:train:239 - [epoch 98]: epoch loss = 0.292870,   acc = 0.949744
[epoch 98]: epoch loss = 0.292870,   acc = 0.949744
Epoch 99/160: 84it [00:09,  8.55it/s]                        
2025-06-18 11:15:58.522 | INFO     | model:train:239 - [epoch 99]: epoch loss = 0.292011,   acc = 0.951557
[epoch 99]: epoch loss = 0.292011,   acc = 0.951557
Epoch 100/160: 84it [00:09,  8.42it/s]                        
2025-06-18 11:16:08.597 | INFO     | model:train:239 - [epoch 100]: epoch loss = 0.290381,   acc = 0.950908
[epoch 100]: epoch loss = 0.290381,   acc = 0.950908
/home/djh/my_envs/dai_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2776: UserWarning: y_pred contains classes not in y_true
  warnings.warn("y_pred contains classes not in y_true")
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([14623,  6151,  5563,  6242, 12478, 15795,  8148, 12380,   248,
        1748,  2365,  4231]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), array([35417,  5127,  3970,  4731,  9297, 12040,  4973,  7258,  1532,
        1652,  3975]))
2025-06-18 11:16:09.045 | INFO     | model:train:255 - [epoch 100]: val loss = 3.956373,   val acc = 0.446917,   val balanced acc = 0.500412
[epoch 100]: val loss = 3.956373,   val acc = 0.446917,   val balanced acc = 0.500412
2025-06-18 11:16:09.083 | INFO     | model:train:275 - EarlyStopping counter: 3 out of 3
EarlyStopping counter: 3 out of 3
2025-06-18 11:16:09.083 | INFO     | model:train:277 - Early stopping triggered.
Early stopping triggered.
