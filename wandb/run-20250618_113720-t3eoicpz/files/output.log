Epoch 1/160: 84it [00:11,  7.49it/s]                        
2025-06-18 11:37:33.233 | INFO     | model:train:239 - [epoch 1]: epoch loss = 2.443289,   acc = 0.163373
[epoch 1]: epoch loss = 2.443289,   acc = 0.163373
Epoch 2/160: 84it [00:10,  8.03it/s]                        
2025-06-18 11:37:43.756 | INFO     | model:train:239 - [epoch 2]: epoch loss = 2.367798,   acc = 0.161765
[epoch 2]: epoch loss = 2.367798,   acc = 0.161765
Epoch 3/160: 84it [00:10,  7.98it/s]                        
2025-06-18 11:37:54.350 | INFO     | model:train:239 - [epoch 3]: epoch loss = 2.344305,   acc = 0.178134
[epoch 3]: epoch loss = 2.344305,   acc = 0.178134
Epoch 4/160: 84it [00:10,  7.91it/s]                        
2025-06-18 11:38:05.034 | INFO     | model:train:239 - [epoch 4]: epoch loss = 2.283879,   acc = 0.184732
[epoch 4]: epoch loss = 2.283879,   acc = 0.184732
Epoch 5/160: 84it [00:10,  8.11it/s]                        
2025-06-18 11:38:15.501 | INFO     | model:train:239 - [epoch 5]: epoch loss = 2.212509,   acc = 0.179387
[epoch 5]: epoch loss = 2.212509,   acc = 0.179387
Epoch 6/160: 84it [00:10,  8.37it/s]                        
2025-06-18 11:38:25.684 | INFO     | model:train:239 - [epoch 6]: epoch loss = 2.108900,   acc = 0.185187
[epoch 6]: epoch loss = 2.108900,   acc = 0.185187
Epoch 7/160: 84it [00:10,  8.03it/s]                        
2025-06-18 11:38:36.216 | INFO     | model:train:239 - [epoch 7]: epoch loss = 1.954768,   acc = 0.279773
[epoch 7]: epoch loss = 1.954768,   acc = 0.279773
Epoch 8/160: 84it [00:10,  7.73it/s]                        
2025-06-18 11:38:47.144 | INFO     | model:train:239 - [epoch 8]: epoch loss = 1.822424,   acc = 0.367104
[epoch 8]: epoch loss = 1.822424,   acc = 0.367104
Epoch 9/160: 84it [00:10,  7.89it/s]                        
2025-06-18 11:38:57.852 | INFO     | model:train:239 - [epoch 9]: epoch loss = 1.722199,   acc = 0.427396
[epoch 9]: epoch loss = 1.722199,   acc = 0.427396
Epoch 10/160: 84it [00:10,  7.65it/s]                        
2025-06-18 11:39:08.977 | INFO     | model:train:239 - [epoch 10]: epoch loss = 1.581355,   acc = 0.519333
[epoch 10]: epoch loss = 1.581355,   acc = 0.519333
Epoch 11/160: 84it [00:10,  7.83it/s]                        
2025-06-18 11:39:19.774 | INFO     | model:train:239 - [epoch 11]: epoch loss = 1.495883,   acc = 0.551200
[epoch 11]: epoch loss = 1.495883,   acc = 0.551200
Epoch 12/160: 84it [00:10,  7.87it/s]                        
2025-06-18 11:39:30.585 | INFO     | model:train:239 - [epoch 12]: epoch loss = 1.413552,   acc = 0.575948
[epoch 12]: epoch loss = 1.413552,   acc = 0.575948
Epoch 13/160: 84it [00:10,  7.88it/s]                        
2025-06-18 11:39:41.319 | INFO     | model:train:239 - [epoch 13]: epoch loss = 1.318341,   acc = 0.618556
[epoch 13]: epoch loss = 1.318341,   acc = 0.618556
Epoch 14/160: 84it [00:10,  7.87it/s]                        
2025-06-18 11:39:52.094 | INFO     | model:train:239 - [epoch 14]: epoch loss = 1.275806,   acc = 0.640488
[epoch 14]: epoch loss = 1.275806,   acc = 0.640488
Epoch 15/160: 84it [00:10,  7.88it/s]                        
2025-06-18 11:40:02.960 | INFO     | model:train:239 - [epoch 15]: epoch loss = 1.264015,   acc = 0.646768
[epoch 15]: epoch loss = 1.264015,   acc = 0.646768
Epoch 16/160: 84it [00:10,  7.96it/s]                        
2025-06-18 11:40:13.584 | INFO     | model:train:239 - [epoch 16]: epoch loss = 1.205038,   acc = 0.663463
[epoch 16]: epoch loss = 1.205038,   acc = 0.663463
Epoch 17/160: 84it [00:10,  8.37it/s]                        
2025-06-18 11:40:23.694 | INFO     | model:train:239 - [epoch 17]: epoch loss = 1.204584,   acc = 0.658158
[epoch 17]: epoch loss = 1.204584,   acc = 0.658158
Epoch 18/160: 84it [00:10,  7.86it/s]                        
2025-06-18 11:40:34.934 | INFO     | model:train:239 - [epoch 18]: epoch loss = 1.194055,   acc = 0.669872
[epoch 18]: epoch loss = 1.194055,   acc = 0.669872
Epoch 19/160: 84it [00:10,  7.92it/s]                        
2025-06-18 11:40:45.669 | INFO     | model:train:239 - [epoch 19]: epoch loss = 1.140511,   acc = 0.685573
[epoch 19]: epoch loss = 1.140511,   acc = 0.685573
Epoch 20/160: 84it [00:10,  7.92it/s]                        
2025-06-18 11:40:56.356 | INFO     | model:train:239 - [epoch 20]: epoch loss = 1.060866,   acc = 0.710324
[epoch 20]: epoch loss = 1.060866,   acc = 0.710324
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 8691,  4938,  4768,  6751, 13194, 14158,  5689,  7399,    20,
         977,  2403,  2987]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 9214,  5780,  4315,  5410, 14621, 13736,  4889,  6822,   112,
        1779,  1347,  3950]))
2025-06-18 11:40:56.692 | INFO     | model:train:255 - [epoch 20]: val loss = 1.835940,   val acc = 0.625717,   val balanced acc = 0.529854
[epoch 20]: val loss = 1.835940,   val acc = 0.625717,   val balanced acc = 0.529854
Epoch 21/160:  44%|████▍     | 36/82 [00:04<00:05,  7.90it/s]wandb: WARNING Tried to log to step 20 that is less than the current step 21. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 21/160: 84it [00:10,  7.90it/s]                        
2025-06-18 11:41:07.510 | INFO     | model:train:239 - [epoch 21]: epoch loss = 1.014555,   acc = 0.731448
[epoch 21]: epoch loss = 1.014555,   acc = 0.731448
Epoch 22/160: 84it [00:10,  7.77it/s]                        
2025-06-18 11:41:18.389 | INFO     | model:train:239 - [epoch 22]: epoch loss = 0.972310,   acc = 0.745622
[epoch 22]: epoch loss = 0.972310,   acc = 0.745622
Epoch 23/160: 84it [00:10,  8.02it/s]                        
2025-06-18 11:41:28.941 | INFO     | model:train:239 - [epoch 23]: epoch loss = 0.919299,   acc = 0.759904
[epoch 23]: epoch loss = 0.919299,   acc = 0.759904
Epoch 24/160: 84it [00:10,  7.85it/s]                        
2025-06-18 11:41:39.726 | INFO     | model:train:239 - [epoch 24]: epoch loss = 0.896638,   acc = 0.771386
[epoch 24]: epoch loss = 0.896638,   acc = 0.771386
Epoch 25/160: 84it [00:10,  7.85it/s]                        
2025-06-18 11:41:50.512 | INFO     | model:train:239 - [epoch 25]: epoch loss = 0.891171,   acc = 0.777706
[epoch 25]: epoch loss = 0.891171,   acc = 0.777706
Epoch 26/160: 84it [00:10,  8.00it/s]                        
2025-06-18 11:42:01.094 | INFO     | model:train:239 - [epoch 26]: epoch loss = 0.930408,   acc = 0.756124
[epoch 26]: epoch loss = 0.930408,   acc = 0.756124
Epoch 27/160: 84it [00:10,  7.84it/s]                        
2025-06-18 11:42:12.068 | INFO     | model:train:239 - [epoch 27]: epoch loss = 0.897773,   acc = 0.770091
[epoch 27]: epoch loss = 0.897773,   acc = 0.770091
Epoch 28/160: 84it [00:10,  7.77it/s]                        
2025-06-18 11:42:22.961 | INFO     | model:train:239 - [epoch 28]: epoch loss = 0.888830,   acc = 0.770039
[epoch 28]: epoch loss = 0.888830,   acc = 0.770039
Epoch 29/160: 84it [00:10,  7.79it/s]                        
2025-06-18 11:42:33.816 | INFO     | model:train:239 - [epoch 29]: epoch loss = 0.852991,   acc = 0.780561
[epoch 29]: epoch loss = 0.852991,   acc = 0.780561
Epoch 30/160: 84it [00:10,  7.91it/s]                        
2025-06-18 11:42:44.526 | INFO     | model:train:239 - [epoch 30]: epoch loss = 0.794309,   acc = 0.804194
[epoch 30]: epoch loss = 0.794309,   acc = 0.804194
Epoch 31/160: 84it [00:10,  7.99it/s]                        
2025-06-18 11:42:55.104 | INFO     | model:train:239 - [epoch 31]: epoch loss = 0.756954,   acc = 0.817252
[epoch 31]: epoch loss = 0.756954,   acc = 0.817252
Epoch 32/160: 84it [00:10,  8.02it/s]                        
2025-06-18 11:43:05.675 | INFO     | model:train:239 - [epoch 32]: epoch loss = 0.731303,   acc = 0.824831
[epoch 32]: epoch loss = 0.731303,   acc = 0.824831
Epoch 33/160: 84it [00:10,  7.88it/s]                        
2025-06-18 11:43:16.410 | INFO     | model:train:239 - [epoch 33]: epoch loss = 0.704343,   acc = 0.834168
[epoch 33]: epoch loss = 0.704343,   acc = 0.834168
Epoch 34/160: 84it [00:10,  7.93it/s]                        
2025-06-18 11:43:27.101 | INFO     | model:train:239 - [epoch 34]: epoch loss = 0.679463,   acc = 0.841344
[epoch 34]: epoch loss = 0.679463,   acc = 0.841344
Epoch 35/160: 84it [00:10,  8.05it/s]                        
2025-06-18 11:43:37.607 | INFO     | model:train:239 - [epoch 35]: epoch loss = 0.682583,   acc = 0.842155
[epoch 35]: epoch loss = 0.682583,   acc = 0.842155
Epoch 36/160: 84it [00:10,  8.01it/s]                        
2025-06-18 11:43:48.195 | INFO     | model:train:239 - [epoch 36]: epoch loss = 0.674369,   acc = 0.843682
[epoch 36]: epoch loss = 0.674369,   acc = 0.843682
Epoch 37/160: 84it [00:10,  8.09it/s]                        
2025-06-18 11:43:58.656 | INFO     | model:train:239 - [epoch 37]: epoch loss = 0.665070,   acc = 0.844488
[epoch 37]: epoch loss = 0.665070,   acc = 0.844488
Epoch 38/160: 84it [00:10,  8.01it/s]                        
2025-06-18 11:44:09.236 | INFO     | model:train:239 - [epoch 38]: epoch loss = 0.653229,   acc = 0.850065
[epoch 38]: epoch loss = 0.653229,   acc = 0.850065
Epoch 39/160: 84it [00:10,  7.84it/s]                        
2025-06-18 11:44:20.041 | INFO     | model:train:239 - [epoch 39]: epoch loss = 0.629121,   acc = 0.857507
[epoch 39]: epoch loss = 0.629121,   acc = 0.857507
Epoch 40/160: 84it [00:10,  8.01it/s]                        
2025-06-18 11:44:30.624 | INFO     | model:train:239 - [epoch 40]: epoch loss = 0.610675,   acc = 0.865035
[epoch 40]: epoch loss = 0.610675,   acc = 0.865035
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 8434,  6169,  5073,  8196, 12393, 13893,  3811,  7533,    49,
        2983,  1390,  2051]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 9214,  5780,  4315,  5410, 14621, 13736,  4889,  6822,   112,
        1779,  1347,  3950]))
2025-06-18 11:44:30.932 | INFO     | model:train:255 - [epoch 40]: val loss = 2.552611,   val acc = 0.588677,   val balanced acc = 0.515550
[epoch 40]: val loss = 2.552611,   val acc = 0.588677,   val balanced acc = 0.515550
2025-06-18 11:44:30.970 | INFO     | model:train:275 - EarlyStopping counter: 1 out of 3
EarlyStopping counter: 1 out of 3
Epoch 41/160:   0%|          | 0/82 [00:00<?, ?it/s]wandb: WARNING Tried to log to step 40 that is less than the current step 41. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 41/160: 84it [00:10,  8.36it/s]                        
2025-06-18 11:44:41.101 | INFO     | model:train:239 - [epoch 41]: epoch loss = 0.600221,   acc = 0.867530
[epoch 41]: epoch loss = 0.600221,   acc = 0.867530
Epoch 42/160: 84it [00:10,  7.93it/s]                        
2025-06-18 11:44:51.975 | INFO     | model:train:239 - [epoch 42]: epoch loss = 0.578140,   acc = 0.872867
[epoch 42]: epoch loss = 0.578140,   acc = 0.872867
Epoch 43/160: 84it [00:10,  8.10it/s]                        
2025-06-18 11:45:02.456 | INFO     | model:train:239 - [epoch 43]: epoch loss = 0.580780,   acc = 0.874126
[epoch 43]: epoch loss = 0.580780,   acc = 0.874126
Epoch 44/160: 84it [00:10,  8.07it/s]                        
2025-06-18 11:45:12.959 | INFO     | model:train:239 - [epoch 44]: epoch loss = 0.603451,   acc = 0.864339
[epoch 44]: epoch loss = 0.603451,   acc = 0.864339
Epoch 45/160: 84it [00:10,  8.02it/s]                        
2025-06-18 11:45:23.947 | INFO     | model:train:239 - [epoch 45]: epoch loss = 0.575170,   acc = 0.872115
[epoch 45]: epoch loss = 0.575170,   acc = 0.872115
Epoch 46/160: 84it [00:10,  8.04it/s]                        
2025-06-18 11:45:34.471 | INFO     | model:train:239 - [epoch 46]: epoch loss = 0.555421,   acc = 0.878718
[epoch 46]: epoch loss = 0.555421,   acc = 0.878718
Epoch 47/160: 84it [00:10,  7.97it/s]                        
2025-06-18 11:45:45.145 | INFO     | model:train:239 - [epoch 47]: epoch loss = 0.533886,   acc = 0.886923
[epoch 47]: epoch loss = 0.533886,   acc = 0.886923
Epoch 48/160: 84it [00:10,  8.23it/s]                        
2025-06-18 11:45:55.439 | INFO     | model:train:239 - [epoch 48]: epoch loss = 0.526884,   acc = 0.890468
[epoch 48]: epoch loss = 0.526884,   acc = 0.890468
Epoch 49/160: 84it [00:10,  8.18it/s]                        
2025-06-18 11:46:05.795 | INFO     | model:train:239 - [epoch 49]: epoch loss = 0.528219,   acc = 0.889924
[epoch 49]: epoch loss = 0.528219,   acc = 0.889924
Epoch 50/160: 84it [00:10,  8.11it/s]                        
2025-06-18 11:46:16.227 | INFO     | model:train:239 - [epoch 50]: epoch loss = 0.699711,   acc = 0.836310
[epoch 50]: epoch loss = 0.699711,   acc = 0.836310
Epoch 51/160: 84it [00:10,  8.08it/s]                        
2025-06-18 11:46:26.719 | INFO     | model:train:239 - [epoch 51]: epoch loss = 0.707758,   acc = 0.828269
[epoch 51]: epoch loss = 0.707758,   acc = 0.828269
Epoch 52/160: 84it [00:10,  8.31it/s]                        
2025-06-18 11:46:36.919 | INFO     | model:train:239 - [epoch 52]: epoch loss = 0.632506,   acc = 0.849945
[epoch 52]: epoch loss = 0.632506,   acc = 0.849945
Epoch 53/160: 84it [00:10,  8.02it/s]                        
2025-06-18 11:46:48.515 | INFO     | model:train:239 - [epoch 53]: epoch loss = 0.547565,   acc = 0.880035
[epoch 53]: epoch loss = 0.547565,   acc = 0.880035
Epoch 54/160: 84it [00:10,  8.04it/s]                        
2025-06-18 11:46:59.051 | INFO     | model:train:239 - [epoch 54]: epoch loss = 0.505083,   acc = 0.893151
[epoch 54]: epoch loss = 0.505083,   acc = 0.893151
Epoch 55/160: 84it [00:10,  8.17it/s]                        
2025-06-18 11:47:09.454 | INFO     | model:train:239 - [epoch 55]: epoch loss = 0.485546,   acc = 0.900622
[epoch 55]: epoch loss = 0.485546,   acc = 0.900622
Epoch 56/160: 84it [00:10,  7.94it/s]                        
2025-06-18 11:47:20.119 | INFO     | model:train:239 - [epoch 56]: epoch loss = 0.470986,   acc = 0.906127
[epoch 56]: epoch loss = 0.470986,   acc = 0.906127
Epoch 57/160: 84it [00:10,  7.85it/s]                        
2025-06-18 11:47:30.963 | INFO     | model:train:239 - [epoch 57]: epoch loss = 0.461748,   acc = 0.908775
[epoch 57]: epoch loss = 0.461748,   acc = 0.908775
Epoch 58/160: 84it [00:10,  7.88it/s]                        
2025-06-18 11:47:41.712 | INFO     | model:train:239 - [epoch 58]: epoch loss = 0.453498,   acc = 0.911771
[epoch 58]: epoch loss = 0.453498,   acc = 0.911771
Epoch 59/160: 84it [00:10,  7.78it/s]                        
2025-06-18 11:47:52.628 | INFO     | model:train:239 - [epoch 59]: epoch loss = 0.443994,   acc = 0.912698
[epoch 59]: epoch loss = 0.443994,   acc = 0.912698
Epoch 60/160: 84it [00:10,  7.71it/s]                        
2025-06-18 11:48:03.615 | INFO     | model:train:239 - [epoch 60]: epoch loss = 0.440844,   acc = 0.914510
[epoch 60]: epoch loss = 0.440844,   acc = 0.914510
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11]), array([ 9580,  5729,  4643,  6515, 12578, 15878,  4353,  6458,  2252,
        1597,  2392]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 9214,  5780,  4315,  5410, 14621, 13736,  4889,  6822,   112,
        1779,  1347,  3950]))
2025-06-18 11:48:03.940 | INFO     | model:train:255 - [epoch 60]: val loss = 2.592377,   val acc = 0.588440,   val balanced acc = 0.499524
[epoch 60]: val loss = 2.592377,   val acc = 0.588440,   val balanced acc = 0.499524
2025-06-18 11:48:04.003 | INFO     | model:train:275 - EarlyStopping counter: 2 out of 3
EarlyStopping counter: 2 out of 3
Epoch 61/160:  68%|██████▊   | 56/82 [00:07<00:03,  7.98it/s]wandb: WARNING Tried to log to step 60 that is less than the current step 61. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
Epoch 61/160: 84it [00:10,  7.81it/s]                        
2025-06-18 11:48:14.950 | INFO     | model:train:239 - [epoch 61]: epoch loss = 0.436437,   acc = 0.917961
[epoch 61]: epoch loss = 0.436437,   acc = 0.917961
Epoch 62/160: 84it [00:10,  7.88it/s]                        
2025-06-18 11:48:25.812 | INFO     | model:train:239 - [epoch 62]: epoch loss = 0.430378,   acc = 0.918257
[epoch 62]: epoch loss = 0.430378,   acc = 0.918257
Epoch 63/160: 84it [00:10,  7.89it/s]                        
2025-06-18 11:48:36.655 | INFO     | model:train:239 - [epoch 63]: epoch loss = 0.421024,   acc = 0.920322
[epoch 63]: epoch loss = 0.421024,   acc = 0.920322
Epoch 64/160: 84it [00:09,  8.55it/s]                        
2025-06-18 11:48:46.576 | INFO     | model:train:239 - [epoch 64]: epoch loss = 0.424193,   acc = 0.921103
[epoch 64]: epoch loss = 0.424193,   acc = 0.921103
Epoch 65/160: 84it [00:10,  7.99it/s]                        
2025-06-18 11:48:57.212 | INFO     | model:train:239 - [epoch 65]: epoch loss = 0.415107,   acc = 0.922746
[epoch 65]: epoch loss = 0.415107,   acc = 0.922746
Epoch 66/160: 84it [00:10,  7.89it/s]                        
2025-06-18 11:49:07.948 | INFO     | model:train:239 - [epoch 66]: epoch loss = 0.408738,   acc = 0.923298
[epoch 66]: epoch loss = 0.408738,   acc = 0.923298
Epoch 67/160: 84it [00:10,  7.82it/s]                        
2025-06-18 11:49:18.805 | INFO     | model:train:239 - [epoch 67]: epoch loss = 0.401873,   acc = 0.924321
[epoch 67]: epoch loss = 0.401873,   acc = 0.924321
Epoch 68/160: 84it [00:10,  7.84it/s]                        
2025-06-18 11:49:29.617 | INFO     | model:train:239 - [epoch 68]: epoch loss = 0.402796,   acc = 0.924965
[epoch 68]: epoch loss = 0.402796,   acc = 0.924965
Epoch 69/160: 84it [00:10,  7.74it/s]                        
2025-06-18 11:49:40.615 | INFO     | model:train:239 - [epoch 69]: epoch loss = 0.400281,   acc = 0.927168
[epoch 69]: epoch loss = 0.400281,   acc = 0.927168
Epoch 70/160: 84it [00:10,  8.30it/s]                        
2025-06-18 11:49:50.835 | INFO     | model:train:239 - [epoch 70]: epoch loss = 0.403072,   acc = 0.927718
[epoch 70]: epoch loss = 0.403072,   acc = 0.927718
Epoch 71/160: 84it [00:10,  8.02it/s]                        
2025-06-18 11:50:01.414 | INFO     | model:train:239 - [epoch 71]: epoch loss = 0.386152,   acc = 0.929468
[epoch 71]: epoch loss = 0.386152,   acc = 0.929468
Epoch 72/160: 84it [00:10,  7.91it/s]                        
2025-06-18 11:50:12.114 | INFO     | model:train:239 - [epoch 72]: epoch loss = 0.381139,   acc = 0.929176
[epoch 72]: epoch loss = 0.381139,   acc = 0.929176
Epoch 73/160: 84it [00:10,  8.23it/s]                        
2025-06-18 11:50:22.455 | INFO     | model:train:239 - [epoch 73]: epoch loss = 0.378358,   acc = 0.930990
[epoch 73]: epoch loss = 0.378358,   acc = 0.930990
Epoch 74/160: 84it [00:10,  8.09it/s]                        
2025-06-18 11:50:33.054 | INFO     | model:train:239 - [epoch 74]: epoch loss = 0.374480,   acc = 0.932276
[epoch 74]: epoch loss = 0.374480,   acc = 0.932276
Epoch 75/160: 84it [00:10,  7.96it/s]                        
2025-06-18 11:50:43.706 | INFO     | model:train:239 - [epoch 75]: epoch loss = 0.371364,   acc = 0.932993
[epoch 75]: epoch loss = 0.371364,   acc = 0.932993
Epoch 76/160: 84it [00:10,  8.04it/s]                        
2025-06-18 11:50:54.242 | INFO     | model:train:239 - [epoch 76]: epoch loss = 0.370078,   acc = 0.934008
[epoch 76]: epoch loss = 0.370078,   acc = 0.934008
Epoch 77/160: 84it [00:10,  7.90it/s]                        
2025-06-18 11:51:04.996 | INFO     | model:train:239 - [epoch 77]: epoch loss = 0.365032,   acc = 0.934431
[epoch 77]: epoch loss = 0.365032,   acc = 0.934431
Epoch 78/160: 84it [00:10,  8.09it/s]                        
2025-06-18 11:51:15.458 | INFO     | model:train:239 - [epoch 78]: epoch loss = 0.367071,   acc = 0.934254
[epoch 78]: epoch loss = 0.367071,   acc = 0.934254
Epoch 79/160: 84it [00:10,  8.01it/s]                        
2025-06-18 11:51:25.983 | INFO     | model:train:239 - [epoch 79]: epoch loss = 0.366614,   acc = 0.932404
[epoch 79]: epoch loss = 0.366614,   acc = 0.932404
Epoch 80/160: 84it [00:10,  7.85it/s]                        
2025-06-18 11:51:36.729 | INFO     | model:train:239 - [epoch 80]: epoch loss = 0.360163,   acc = 0.934070
[epoch 80]: epoch loss = 0.360163,   acc = 0.934070
Predicted labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 9152,  4817,  4918,  7356, 12772, 15079,  5115,  6338,    94,
        2641,  1754,  1939]))
True labels distribution: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 9214,  5780,  4315,  5410, 14621, 13736,  4889,  6822,   112,
        1779,  1347,  3950]))
2025-06-18 11:51:37.025 | INFO     | model:train:255 - [epoch 80]: val loss = 2.693837,   val acc = 0.568892,   val balanced acc = 0.484986
[epoch 80]: val loss = 2.693837,   val acc = 0.568892,   val balanced acc = 0.484986
2025-06-18 11:51:37.084 | INFO     | model:train:275 - EarlyStopping counter: 3 out of 3
EarlyStopping counter: 3 out of 3
2025-06-18 11:51:37.085 | INFO     | model:train:277 - Early stopping triggered.
Early stopping triggered.
