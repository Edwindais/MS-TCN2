2025-06-08 22:25:49.667 | INFO     | model:train:237 - [epoch 1]: epoch loss = 2.441280,   acc = 0.149599
2025-06-08 22:26:00.125 | INFO     | model:train:237 - [epoch 2]: epoch loss = 2.348247,   acc = 0.164166
2025-06-08 22:26:10.474 | INFO     | model:train:237 - [epoch 3]: epoch loss = 2.300197,   acc = 0.176612
2025-06-08 22:26:20.776 | INFO     | model:train:237 - [epoch 4]: epoch loss = 2.213513,   acc = 0.192179
2025-06-08 22:26:30.935 | INFO     | model:train:237 - [epoch 5]: epoch loss = 2.063505,   acc = 0.192336
2025-06-08 22:26:41.128 | INFO     | model:train:237 - [epoch 6]: epoch loss = 1.925350,   acc = 0.287818
2025-06-08 22:26:51.584 | INFO     | model:train:237 - [epoch 7]: epoch loss = 1.698126,   acc = 0.443421
2025-06-08 22:27:02.304 | INFO     | model:train:237 - [epoch 8]: epoch loss = 1.560067,   acc = 0.526014
2025-06-08 22:27:12.967 | INFO     | model:train:237 - [epoch 9]: epoch loss = 1.434158,   acc = 0.571295
2025-06-08 22:27:23.892 | INFO     | model:train:237 - [epoch 10]: epoch loss = 1.482259,   acc = 0.545554
2025-06-08 22:27:34.400 | INFO     | model:train:237 - [epoch 11]: epoch loss = 1.319238,   acc = 0.616354
2025-06-08 22:27:44.836 | INFO     | model:train:237 - [epoch 12]: epoch loss = 1.245385,   acc = 0.641381
2025-06-08 22:27:55.421 | INFO     | model:train:237 - [epoch 13]: epoch loss = 1.175647,   acc = 0.665245
2025-06-08 22:28:05.861 | INFO     | model:train:237 - [epoch 14]: epoch loss = 1.105067,   acc = 0.693500
2025-06-08 22:28:16.681 | INFO     | model:train:237 - [epoch 15]: epoch loss = 1.098688,   acc = 0.702702
2025-06-08 22:28:27.071 | INFO     | model:train:237 - [epoch 16]: epoch loss = 1.095865,   acc = 0.699638
2025-06-08 22:28:37.036 | INFO     | model:train:237 - [epoch 17]: epoch loss = 1.079692,   acc = 0.706511
2025-06-08 22:28:47.470 | INFO     | model:train:237 - [epoch 18]: epoch loss = 1.044817,   acc = 0.725196
2025-06-08 22:28:57.905 | INFO     | model:train:237 - [epoch 19]: epoch loss = 0.953376,   acc = 0.744994
2025-06-08 22:29:08.461 | INFO     | model:train:237 - [epoch 20]: epoch loss = 0.892479,   acc = 0.768562
2025-06-08 22:29:08.830 | INFO     | model:train:245 - [epoch 20]: val loss = 2.400072,   val acc = 0.573586,   val balanced acc = 0.561132
2025-06-08 22:29:19.607 | INFO     | model:train:237 - [epoch 21]: epoch loss = 0.856490,   acc = 0.785526
2025-06-08 22:29:30.253 | INFO     | model:train:237 - [epoch 22]: epoch loss = 0.865827,   acc = 0.775554
2025-06-08 22:29:40.716 | INFO     | model:train:237 - [epoch 23]: epoch loss = 0.832974,   acc = 0.791801
2025-06-08 22:29:51.287 | INFO     | model:train:237 - [epoch 24]: epoch loss = 0.774877,   acc = 0.809757
2025-06-08 22:30:01.741 | INFO     | model:train:237 - [epoch 25]: epoch loss = 0.843856,   acc = 0.786162
2025-06-08 22:30:12.277 | INFO     | model:train:237 - [epoch 26]: epoch loss = 1.000614,   acc = 0.726537
2025-06-08 22:30:22.576 | INFO     | model:train:237 - [epoch 27]: epoch loss = 0.866944,   acc = 0.773341
2025-06-08 22:30:32.996 | INFO     | model:train:237 - [epoch 28]: epoch loss = 0.750378,   acc = 0.814645
2025-06-08 22:30:43.479 | INFO     | model:train:237 - [epoch 29]: epoch loss = 0.686837,   acc = 0.834051
2025-06-08 22:30:54.024 | INFO     | model:train:237 - [epoch 30]: epoch loss = 0.645059,   acc = 0.850770
2025-06-08 22:31:03.977 | INFO     | model:train:237 - [epoch 31]: epoch loss = 0.648174,   acc = 0.852935
2025-06-08 22:31:14.136 | INFO     | model:train:237 - [epoch 32]: epoch loss = 0.676417,   acc = 0.840973
2025-06-08 22:31:24.680 | INFO     | model:train:237 - [epoch 33]: epoch loss = 0.632454,   acc = 0.856006
2025-06-08 22:31:35.190 | INFO     | model:train:237 - [epoch 34]: epoch loss = 0.572727,   acc = 0.870943
2025-06-08 22:31:45.611 | INFO     | model:train:237 - [epoch 35]: epoch loss = 0.562247,   acc = 0.881359
2025-06-08 22:31:56.160 | INFO     | model:train:237 - [epoch 36]: epoch loss = 0.536605,   acc = 0.886214
2025-06-08 22:32:06.643 | INFO     | model:train:237 - [epoch 37]: epoch loss = 0.533957,   acc = 0.887126
2025-06-08 22:32:17.005 | INFO     | model:train:237 - [epoch 38]: epoch loss = 0.515979,   acc = 0.891579
2025-06-08 22:32:27.624 | INFO     | model:train:237 - [epoch 39]: epoch loss = 0.510785,   acc = 0.891918
2025-06-08 22:32:38.103 | INFO     | model:train:237 - [epoch 40]: epoch loss = 0.505770,   acc = 0.895640
2025-06-08 22:32:38.438 | INFO     | model:train:245 - [epoch 40]: val loss = 2.378112,   val acc = 0.594068,   val balanced acc = 0.565116
2025-06-08 22:32:49.142 | INFO     | model:train:237 - [epoch 41]: epoch loss = 0.488356,   acc = 0.899816
2025-06-08 22:32:59.914 | INFO     | model:train:237 - [epoch 42]: epoch loss = 0.464601,   acc = 0.905343
2025-06-08 22:33:10.611 | INFO     | model:train:237 - [epoch 43]: epoch loss = 0.451718,   acc = 0.909240
2025-06-08 22:33:21.031 | INFO     | model:train:237 - [epoch 44]: epoch loss = 0.438296,   acc = 0.912971
2025-06-08 22:33:31.426 | INFO     | model:train:237 - [epoch 45]: epoch loss = 0.430076,   acc = 0.917312
2025-06-08 22:33:41.980 | INFO     | model:train:237 - [epoch 46]: epoch loss = 0.423777,   acc = 0.919638
2025-06-08 22:33:52.757 | INFO     | model:train:237 - [epoch 47]: epoch loss = 0.410498,   acc = 0.919433
2025-06-08 22:34:03.208 | INFO     | model:train:237 - [epoch 48]: epoch loss = 0.405291,   acc = 0.921864
2025-06-08 22:34:13.623 | INFO     | model:train:237 - [epoch 49]: epoch loss = 0.400525,   acc = 0.922834
2025-06-08 22:34:24.113 | INFO     | model:train:237 - [epoch 50]: epoch loss = 0.386088,   acc = 0.926729
2025-06-08 22:34:34.597 | INFO     | model:train:237 - [epoch 51]: epoch loss = 0.395197,   acc = 0.924189
2025-06-08 22:34:44.677 | INFO     | model:train:237 - [epoch 52]: epoch loss = 0.406720,   acc = 0.918961
2025-06-08 22:34:54.957 | INFO     | model:train:237 - [epoch 53]: epoch loss = 0.387450,   acc = 0.923902
2025-06-08 22:35:05.431 | INFO     | model:train:237 - [epoch 54]: epoch loss = 0.367123,   acc = 0.930929
2025-06-08 22:35:16.104 | INFO     | model:train:237 - [epoch 55]: epoch loss = 0.357711,   acc = 0.933921
2025-06-08 22:35:26.687 | INFO     | model:train:237 - [epoch 56]: epoch loss = 0.350792,   acc = 0.935938
2025-06-08 22:35:37.320 | INFO     | model:train:237 - [epoch 57]: epoch loss = 0.345140,   acc = 0.936553
2025-06-08 22:35:47.918 | INFO     | model:train:237 - [epoch 58]: epoch loss = 0.336112,   acc = 0.939513
2025-06-08 22:35:58.312 | INFO     | model:train:237 - [epoch 59]: epoch loss = 0.332764,   acc = 0.941201
2025-06-08 22:36:08.873 | INFO     | model:train:237 - [epoch 60]: epoch loss = 0.331841,   acc = 0.940481
2025-06-08 22:36:09.208 | INFO     | model:train:245 - [epoch 60]: val loss = 2.919984,   val acc = 0.594935,   val balanced acc = 0.566293
2025-06-08 22:36:19.903 | INFO     | model:train:237 - [epoch 61]: epoch loss = 0.324963,   acc = 0.942384
2025-06-08 22:36:30.583 | INFO     | model:train:237 - [epoch 62]: epoch loss = 0.322172,   acc = 0.941429
2025-06-08 22:36:41.413 | INFO     | model:train:237 - [epoch 63]: epoch loss = 0.310564,   acc = 0.944385
2025-06-08 22:36:51.871 | INFO     | model:train:237 - [epoch 64]: epoch loss = 0.309346,   acc = 0.946337
2025-06-08 22:37:02.436 | INFO     | model:train:237 - [epoch 65]: epoch loss = 0.312081,   acc = 0.944604
2025-06-08 22:37:12.946 | INFO     | model:train:237 - [epoch 66]: epoch loss = 0.312453,   acc = 0.942652
2025-06-08 22:37:23.202 | INFO     | model:train:237 - [epoch 67]: epoch loss = 0.313165,   acc = 0.942308
2025-06-08 22:37:33.755 | INFO     | model:train:237 - [epoch 68]: epoch loss = 0.306915,   acc = 0.946053
2025-06-08 22:37:44.411 | INFO     | model:train:237 - [epoch 69]: epoch loss = 0.316862,   acc = 0.941278
2025-06-08 22:37:54.430 | INFO     | model:train:237 - [epoch 70]: epoch loss = 0.357764,   acc = 0.931019
2025-06-08 22:38:05.111 | INFO     | model:train:237 - [epoch 71]: epoch loss = 0.426788,   acc = 0.906284
2025-06-08 22:38:15.794 | INFO     | model:train:237 - [epoch 72]: epoch loss = 0.381119,   acc = 0.917617
2025-06-08 22:38:26.363 | INFO     | model:train:237 - [epoch 73]: epoch loss = 0.330583,   acc = 0.934548
2025-06-08 22:38:37.019 | INFO     | model:train:237 - [epoch 74]: epoch loss = 0.294881,   acc = 0.946466
2025-06-08 22:38:47.577 | INFO     | model:train:237 - [epoch 75]: epoch loss = 0.282059,   acc = 0.951537
2025-06-08 22:38:57.979 | INFO     | model:train:237 - [epoch 76]: epoch loss = 0.276753,   acc = 0.953746
2025-06-08 22:39:08.360 | INFO     | model:train:237 - [epoch 77]: epoch loss = 0.276056,   acc = 0.953283
2025-06-08 22:39:18.840 | INFO     | model:train:237 - [epoch 78]: epoch loss = 0.270677,   acc = 0.955411
2025-06-08 22:39:29.487 | INFO     | model:train:237 - [epoch 79]: epoch loss = 0.261004,   acc = 0.956898
2025-06-08 22:39:40.079 | INFO     | model:train:237 - [epoch 80]: epoch loss = 0.257663,   acc = 0.958697
2025-06-08 22:39:40.436 | INFO     | model:train:245 - [epoch 80]: val loss = 2.609449,   val acc = 0.600843,   val balanced acc = 0.565301
2025-06-08 22:39:40.554 | INFO     | model:train:258 - EarlyStopping counter: 1 out of 3
2025-06-08 22:39:51.204 | INFO     | model:train:237 - [epoch 81]: epoch loss = 0.255317,   acc = 0.958119
2025-06-08 22:40:01.753 | INFO     | model:train:237 - [epoch 82]: epoch loss = 0.248840,   acc = 0.959874
2025-06-08 22:40:12.482 | INFO     | model:train:237 - [epoch 83]: epoch loss = 0.248038,   acc = 0.960352
2025-06-08 22:40:22.837 | INFO     | model:train:237 - [epoch 84]: epoch loss = 0.247090,   acc = 0.960906
2025-06-08 22:40:33.307 | INFO     | model:train:237 - [epoch 85]: epoch loss = 0.246230,   acc = 0.960684
2025-06-08 22:40:43.980 | INFO     | model:train:237 - [epoch 86]: epoch loss = 0.243776,   acc = 0.960860
2025-06-08 22:40:54.453 | INFO     | model:train:237 - [epoch 87]: epoch loss = 0.243353,   acc = 0.960804
2025-06-08 22:41:05.196 | INFO     | model:train:237 - [epoch 88]: epoch loss = 0.236945,   acc = 0.961531
2025-06-08 22:41:15.666 | INFO     | model:train:237 - [epoch 89]: epoch loss = 0.239669,   acc = 0.962207
2025-06-08 22:41:26.369 | INFO     | model:train:237 - [epoch 90]: epoch loss = 0.236896,   acc = 0.962588
2025-06-08 22:41:37.238 | INFO     | model:train:237 - [epoch 91]: epoch loss = 0.229644,   acc = 0.963547
2025-06-08 22:41:47.648 | INFO     | model:train:237 - [epoch 92]: epoch loss = 0.231236,   acc = 0.963566
2025-06-08 22:41:58.341 | INFO     | model:train:237 - [epoch 93]: epoch loss = 0.228895,   acc = 0.963902
2025-06-08 22:42:08.966 | INFO     | model:train:237 - [epoch 94]: epoch loss = 0.231254,   acc = 0.963418
2025-06-08 22:42:19.656 | INFO     | model:train:237 - [epoch 95]: epoch loss = 0.229401,   acc = 0.963248
2025-06-08 22:42:30.361 | INFO     | model:train:237 - [epoch 96]: epoch loss = 0.226527,   acc = 0.964559
2025-06-08 22:42:40.955 | INFO     | model:train:237 - [epoch 97]: epoch loss = 0.227266,   acc = 0.964788
2025-06-08 22:42:51.339 | INFO     | model:train:237 - [epoch 98]: epoch loss = 0.224391,   acc = 0.965687
2025-06-08 22:43:02.005 | INFO     | model:train:237 - [epoch 99]: epoch loss = 0.223705,   acc = 0.965172
2025-06-08 22:43:12.690 | INFO     | model:train:237 - [epoch 100]: epoch loss = 0.220047,   acc = 0.965293
2025-06-08 22:43:13.054 | INFO     | model:train:245 - [epoch 100]: val loss = 3.226217,   val acc = 0.598073,   val balanced acc = 0.564808
2025-06-08 22:43:13.172 | INFO     | model:train:258 - EarlyStopping counter: 2 out of 3
2025-06-08 22:43:23.796 | INFO     | model:train:237 - [epoch 101]: epoch loss = 0.220440,   acc = 0.965983
2025-06-08 22:43:34.386 | INFO     | model:train:237 - [epoch 102]: epoch loss = 0.215864,   acc = 0.966385
2025-06-08 22:43:44.634 | INFO     | model:train:237 - [epoch 103]: epoch loss = 0.222892,   acc = 0.966208
2025-06-08 22:43:55.118 | INFO     | model:train:237 - [epoch 104]: epoch loss = 0.217359,   acc = 0.966320
2025-06-08 22:44:05.705 | INFO     | model:train:237 - [epoch 105]: epoch loss = 0.213597,   acc = 0.967089
2025-06-08 22:44:16.228 | INFO     | model:train:237 - [epoch 106]: epoch loss = 0.215573,   acc = 0.967764
2025-06-08 22:44:26.878 | INFO     | model:train:237 - [epoch 107]: epoch loss = 0.209434,   acc = 0.967895
2025-06-08 22:44:37.479 | INFO     | model:train:237 - [epoch 108]: epoch loss = 0.209594,   acc = 0.967852
2025-06-08 22:44:48.132 | INFO     | model:train:237 - [epoch 109]: epoch loss = 0.212253,   acc = 0.967845
2025-06-08 22:44:58.234 | INFO     | model:train:237 - [epoch 110]: epoch loss = 0.213901,   acc = 0.967924
2025-06-08 22:45:08.776 | INFO     | model:train:237 - [epoch 111]: epoch loss = 0.206467,   acc = 0.968532
2025-06-08 22:45:19.453 | INFO     | model:train:237 - [epoch 112]: epoch loss = 0.207747,   acc = 0.968831
2025-06-08 22:45:30.128 | INFO     | model:train:237 - [epoch 113]: epoch loss = 0.206250,   acc = 0.969208
2025-06-08 22:45:40.863 | INFO     | model:train:237 - [epoch 114]: epoch loss = 0.201113,   acc = 0.970162
2025-06-08 22:45:51.411 | INFO     | model:train:237 - [epoch 115]: epoch loss = 0.204309,   acc = 0.970112
2025-06-08 22:46:01.993 | INFO     | model:train:237 - [epoch 116]: epoch loss = 0.202982,   acc = 0.969523
2025-06-08 22:46:12.549 | INFO     | model:train:237 - [epoch 117]: epoch loss = 0.200674,   acc = 0.970187
2025-06-08 22:46:23.143 | INFO     | model:train:237 - [epoch 118]: epoch loss = 0.199522,   acc = 0.970566
2025-06-08 22:46:33.736 | INFO     | model:train:237 - [epoch 119]: epoch loss = 0.199634,   acc = 0.970523
2025-06-08 22:46:44.285 | INFO     | model:train:237 - [epoch 120]: epoch loss = 0.198748,   acc = 0.970544
2025-06-08 22:46:44.642 | INFO     | model:train:245 - [epoch 120]: val loss = 3.119132,   val acc = 0.587543,   val balanced acc = 0.556560
2025-06-08 22:46:44.679 | INFO     | model:train:258 - EarlyStopping counter: 3 out of 3
2025-06-08 22:46:44.679 | INFO     | model:train:260 - Early stopping triggered.
