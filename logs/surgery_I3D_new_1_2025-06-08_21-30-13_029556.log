2025-06-08 21:30:52.922 | INFO     | model:train:237 - [epoch 1]: epoch loss = 2.441719,   acc = 0.153438
2025-06-08 21:31:03.702 | INFO     | model:train:237 - [epoch 2]: epoch loss = 2.344179,   acc = 0.168891
2025-06-08 21:31:14.175 | INFO     | model:train:237 - [epoch 3]: epoch loss = 2.285938,   acc = 0.182231
2025-06-08 21:31:24.900 | INFO     | model:train:237 - [epoch 4]: epoch loss = 2.195755,   acc = 0.181677
2025-06-08 21:31:35.220 | INFO     | model:train:237 - [epoch 5]: epoch loss = 2.102839,   acc = 0.196590
2025-06-08 21:31:45.317 | INFO     | model:train:237 - [epoch 6]: epoch loss = 1.909236,   acc = 0.299764
2025-06-08 21:31:55.982 | INFO     | model:train:237 - [epoch 7]: epoch loss = 1.736702,   acc = 0.423566
2025-06-08 21:32:06.886 | INFO     | model:train:237 - [epoch 8]: epoch loss = 1.575248,   acc = 0.509372
2025-06-08 21:32:17.590 | INFO     | model:train:237 - [epoch 9]: epoch loss = 1.473962,   acc = 0.560097
2025-06-08 21:32:28.947 | INFO     | model:train:237 - [epoch 10]: epoch loss = 1.420188,   acc = 0.585591
2025-06-08 21:32:39.476 | INFO     | model:train:237 - [epoch 11]: epoch loss = 1.314266,   acc = 0.625760
2025-06-08 21:32:49.873 | INFO     | model:train:237 - [epoch 12]: epoch loss = 1.230464,   acc = 0.652735
2025-06-08 21:33:00.563 | INFO     | model:train:237 - [epoch 13]: epoch loss = 1.171643,   acc = 0.677898
2025-06-08 21:33:11.176 | INFO     | model:train:237 - [epoch 14]: epoch loss = 1.200797,   acc = 0.658627
2025-06-08 21:33:21.900 | INFO     | model:train:237 - [epoch 15]: epoch loss = 1.165839,   acc = 0.680535
2025-06-08 21:33:32.530 | INFO     | model:train:237 - [epoch 16]: epoch loss = 1.077752,   acc = 0.709206
2025-06-08 21:33:42.767 | INFO     | model:train:237 - [epoch 17]: epoch loss = 1.046578,   acc = 0.709556
2025-06-08 21:33:53.658 | INFO     | model:train:237 - [epoch 18]: epoch loss = 0.984842,   acc = 0.738309
2025-06-08 21:34:04.374 | INFO     | model:train:237 - [epoch 19]: epoch loss = 0.938116,   acc = 0.753882
2025-06-08 21:34:15.234 | INFO     | model:train:237 - [epoch 20]: epoch loss = 0.945210,   acc = 0.753343
2025-06-08 21:34:17.787 | INFO     | model:train:245 - [epoch 20]: val loss = 1.892574,   val acc = 0.627998,   val balanced acc = 0.528772
2025-06-08 21:34:28.215 | INFO     | model:train:237 - [epoch 21]: epoch loss = 0.885621,   acc = 0.772874
2025-06-08 21:34:39.023 | INFO     | model:train:237 - [epoch 22]: epoch loss = 0.835755,   acc = 0.788427
2025-06-08 21:34:49.466 | INFO     | model:train:237 - [epoch 23]: epoch loss = 0.813969,   acc = 0.797146
2025-06-08 21:35:00.122 | INFO     | model:train:237 - [epoch 24]: epoch loss = 0.882851,   acc = 0.769841
2025-06-08 21:35:10.887 | INFO     | model:train:237 - [epoch 25]: epoch loss = 0.790827,   acc = 0.804553
2025-06-08 21:35:21.629 | INFO     | model:train:237 - [epoch 26]: epoch loss = 0.764501,   acc = 0.814191
2025-06-08 21:35:32.443 | INFO     | model:train:237 - [epoch 27]: epoch loss = 0.839230,   acc = 0.783276
2025-06-08 21:35:43.177 | INFO     | model:train:237 - [epoch 28]: epoch loss = 0.759203,   acc = 0.813883
2025-06-08 21:35:53.818 | INFO     | model:train:237 - [epoch 29]: epoch loss = 0.695752,   acc = 0.837551
2025-06-08 21:36:04.482 | INFO     | model:train:237 - [epoch 30]: epoch loss = 0.647343,   acc = 0.848280
2025-06-08 21:36:15.083 | INFO     | model:train:237 - [epoch 31]: epoch loss = 0.636879,   acc = 0.857992
2025-06-08 21:36:26.389 | INFO     | model:train:237 - [epoch 32]: epoch loss = 0.609759,   acc = 0.864179
2025-06-08 21:36:37.032 | INFO     | model:train:237 - [epoch 33]: epoch loss = 0.596674,   acc = 0.867754
2025-06-08 21:36:47.820 | INFO     | model:train:237 - [epoch 34]: epoch loss = 0.591493,   acc = 0.865415
2025-06-08 21:36:58.923 | INFO     | model:train:237 - [epoch 35]: epoch loss = 0.595678,   acc = 0.865556
2025-06-08 21:37:09.520 | INFO     | model:train:237 - [epoch 36]: epoch loss = 0.579972,   acc = 0.873070
2025-06-08 21:37:20.065 | INFO     | model:train:237 - [epoch 37]: epoch loss = 0.547357,   acc = 0.880122
2025-06-08 21:37:30.837 | INFO     | model:train:237 - [epoch 38]: epoch loss = 0.549310,   acc = 0.878742
2025-06-08 21:37:41.481 | INFO     | model:train:237 - [epoch 39]: epoch loss = 0.518897,   acc = 0.889789
2025-06-08 21:37:52.047 | INFO     | model:train:237 - [epoch 40]: epoch loss = 0.512785,   acc = 0.891412
2025-06-08 21:37:52.410 | INFO     | model:train:245 - [epoch 40]: val loss = 1.971019,   val acc = 0.650339,   val balanced acc = 0.555219
2025-06-08 21:38:03.003 | INFO     | model:train:237 - [epoch 41]: epoch loss = 0.486963,   acc = 0.899269
2025-06-08 21:38:13.617 | INFO     | model:train:237 - [epoch 42]: epoch loss = 0.468479,   acc = 0.904420
2025-06-08 21:38:24.323 | INFO     | model:train:237 - [epoch 43]: epoch loss = 0.453652,   acc = 0.906860
2025-06-08 21:38:35.073 | INFO     | model:train:237 - [epoch 44]: epoch loss = 0.447392,   acc = 0.909348
2025-06-08 21:38:45.613 | INFO     | model:train:237 - [epoch 45]: epoch loss = 0.453354,   acc = 0.906730
2025-06-08 21:38:55.762 | INFO     | model:train:237 - [epoch 46]: epoch loss = 0.437743,   acc = 0.914041
2025-06-08 21:39:06.208 | INFO     | model:train:237 - [epoch 47]: epoch loss = 0.416224,   acc = 0.918481
2025-06-08 21:39:16.746 | INFO     | model:train:237 - [epoch 48]: epoch loss = 0.407867,   acc = 0.921224
2025-06-08 21:39:26.944 | INFO     | model:train:237 - [epoch 49]: epoch loss = 0.404920,   acc = 0.925174
2025-06-08 21:39:37.245 | INFO     | model:train:237 - [epoch 50]: epoch loss = 0.387256,   acc = 0.927049
2025-06-08 21:39:48.227 | INFO     | model:train:237 - [epoch 51]: epoch loss = 0.390951,   acc = 0.924774
2025-06-08 21:39:58.803 | INFO     | model:train:237 - [epoch 52]: epoch loss = 0.389272,   acc = 0.927857
2025-06-08 21:40:09.541 | INFO     | model:train:237 - [epoch 53]: epoch loss = 0.376926,   acc = 0.927304
2025-06-08 21:40:20.083 | INFO     | model:train:237 - [epoch 54]: epoch loss = 0.369973,   acc = 0.929875
2025-06-08 21:40:30.603 | INFO     | model:train:237 - [epoch 55]: epoch loss = 0.355375,   acc = 0.933150
2025-06-08 21:40:41.753 | INFO     | model:train:237 - [epoch 56]: epoch loss = 0.341031,   acc = 0.937604
2025-06-08 21:40:52.344 | INFO     | model:train:237 - [epoch 57]: epoch loss = 0.336951,   acc = 0.940245
2025-06-08 21:41:03.696 | INFO     | model:train:237 - [epoch 58]: epoch loss = 0.329902,   acc = 0.941541
2025-06-08 21:41:14.976 | INFO     | model:train:237 - [epoch 59]: epoch loss = 0.331008,   acc = 0.941472
2025-06-08 21:41:26.321 | INFO     | model:train:237 - [epoch 60]: epoch loss = 0.329013,   acc = 0.940302
2025-06-08 21:41:26.663 | INFO     | model:train:245 - [epoch 60]: val loss = 2.416449,   val acc = 0.651552,   val balanced acc = 0.552585
2025-06-08 21:41:26.703 | INFO     | model:train:258 - EarlyStopping counter: 1 out of 3
2025-06-08 21:41:37.693 | INFO     | model:train:237 - [epoch 61]: epoch loss = 0.321258,   acc = 0.942496
2025-06-08 21:41:48.804 | INFO     | model:train:237 - [epoch 62]: epoch loss = 0.323067,   acc = 0.941647
2025-06-08 21:41:59.734 | INFO     | model:train:237 - [epoch 63]: epoch loss = 0.325381,   acc = 0.939881
2025-06-08 21:42:10.153 | INFO     | model:train:237 - [epoch 64]: epoch loss = 0.329192,   acc = 0.939324
2025-06-08 21:42:20.758 | INFO     | model:train:237 - [epoch 65]: epoch loss = 0.308020,   acc = 0.945511
2025-06-08 21:42:31.571 | INFO     | model:train:237 - [epoch 66]: epoch loss = 0.301560,   acc = 0.947547
2025-06-08 21:42:42.287 | INFO     | model:train:237 - [epoch 67]: epoch loss = 0.294867,   acc = 0.948970
2025-06-08 21:42:53.122 | INFO     | model:train:237 - [epoch 68]: epoch loss = 0.290908,   acc = 0.949025
2025-06-08 21:43:03.877 | INFO     | model:train:237 - [epoch 69]: epoch loss = 0.287002,   acc = 0.950825
2025-06-08 21:43:13.814 | INFO     | model:train:237 - [epoch 70]: epoch loss = 0.292464,   acc = 0.950802
2025-06-08 21:43:24.738 | INFO     | model:train:237 - [epoch 71]: epoch loss = 0.286833,   acc = 0.950258
2025-06-08 21:43:35.589 | INFO     | model:train:237 - [epoch 72]: epoch loss = 0.275128,   acc = 0.952223
2025-06-08 21:43:46.988 | INFO     | model:train:237 - [epoch 73]: epoch loss = 0.269083,   acc = 0.954946
2025-06-08 21:43:57.525 | INFO     | model:train:237 - [epoch 74]: epoch loss = 0.265814,   acc = 0.956165
2025-06-08 21:44:08.388 | INFO     | model:train:237 - [epoch 75]: epoch loss = 0.261556,   acc = 0.957002
2025-06-08 21:44:19.086 | INFO     | model:train:237 - [epoch 76]: epoch loss = 0.257588,   acc = 0.957818
2025-06-08 21:44:30.058 | INFO     | model:train:237 - [epoch 77]: epoch loss = 0.264427,   acc = 0.954941
2025-06-08 21:44:40.612 | INFO     | model:train:237 - [epoch 78]: epoch loss = 0.264246,   acc = 0.956406
2025-06-08 21:44:51.453 | INFO     | model:train:237 - [epoch 79]: epoch loss = 0.255314,   acc = 0.957383
2025-06-08 21:45:02.416 | INFO     | model:train:237 - [epoch 80]: epoch loss = 0.253582,   acc = 0.957259
2025-06-08 21:45:02.776 | INFO     | model:train:245 - [epoch 80]: val loss = 2.613869,   val acc = 0.621577,   val balanced acc = 0.543161
2025-06-08 21:45:02.839 | INFO     | model:train:258 - EarlyStopping counter: 2 out of 3
2025-06-08 21:45:13.826 | INFO     | model:train:237 - [epoch 81]: epoch loss = 0.253388,   acc = 0.957045
2025-06-08 21:45:24.424 | INFO     | model:train:237 - [epoch 82]: epoch loss = 0.250980,   acc = 0.959809
2025-06-08 21:45:35.165 | INFO     | model:train:237 - [epoch 83]: epoch loss = 0.238999,   acc = 0.962075
2025-06-08 21:45:45.633 | INFO     | model:train:237 - [epoch 84]: epoch loss = 0.245624,   acc = 0.960856
2025-06-08 21:45:56.336 | INFO     | model:train:237 - [epoch 85]: epoch loss = 0.240800,   acc = 0.961883
2025-06-08 21:46:06.949 | INFO     | model:train:237 - [epoch 86]: epoch loss = 0.234262,   acc = 0.962908
2025-06-08 21:46:17.698 | INFO     | model:train:237 - [epoch 87]: epoch loss = 0.231254,   acc = 0.962853
2025-06-08 21:46:28.392 | INFO     | model:train:237 - [epoch 88]: epoch loss = 0.229850,   acc = 0.963865
2025-06-08 21:46:39.134 | INFO     | model:train:237 - [epoch 89]: epoch loss = 0.231435,   acc = 0.963760
2025-06-08 21:46:49.794 | INFO     | model:train:237 - [epoch 90]: epoch loss = 0.233770,   acc = 0.962914
2025-06-08 21:47:00.751 | INFO     | model:train:237 - [epoch 91]: epoch loss = 0.228791,   acc = 0.962685
2025-06-08 21:47:11.537 | INFO     | model:train:237 - [epoch 92]: epoch loss = 0.235067,   acc = 0.960716
2025-06-08 21:47:22.316 | INFO     | model:train:237 - [epoch 93]: epoch loss = 0.230400,   acc = 0.961959
2025-06-08 21:47:32.950 | INFO     | model:train:237 - [epoch 94]: epoch loss = 0.223694,   acc = 0.965333
2025-06-08 21:47:43.535 | INFO     | model:train:237 - [epoch 95]: epoch loss = 0.220158,   acc = 0.966050
2025-06-08 21:47:54.449 | INFO     | model:train:237 - [epoch 96]: epoch loss = 0.217647,   acc = 0.966379
2025-06-08 21:48:05.311 | INFO     | model:train:237 - [epoch 97]: epoch loss = 0.217311,   acc = 0.966617
2025-06-08 21:48:16.044 | INFO     | model:train:237 - [epoch 98]: epoch loss = 0.215030,   acc = 0.967262
2025-06-08 21:48:26.553 | INFO     | model:train:237 - [epoch 99]: epoch loss = 0.214614,   acc = 0.967261
2025-06-08 21:48:37.605 | INFO     | model:train:237 - [epoch 100]: epoch loss = 0.209440,   acc = 0.967739
2025-06-08 21:48:37.955 | INFO     | model:train:245 - [epoch 100]: val loss = 2.853624,   val acc = 0.637318,   val balanced acc = 0.530818
2025-06-08 21:48:37.991 | INFO     | model:train:258 - EarlyStopping counter: 3 out of 3
2025-06-08 21:48:37.991 | INFO     | model:train:260 - Early stopping triggered.
