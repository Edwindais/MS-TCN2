2025-06-18 10:38:05.419 | INFO     | model:train:239 - [epoch 1]: epoch loss = 2.435101,   acc = 0.159565
2025-06-18 10:38:15.736 | INFO     | model:train:239 - [epoch 2]: epoch loss = 2.356635,   acc = 0.167936
2025-06-18 10:38:25.955 | INFO     | model:train:239 - [epoch 3]: epoch loss = 2.315885,   acc = 0.173504
2025-06-18 10:38:36.220 | INFO     | model:train:239 - [epoch 4]: epoch loss = 2.269906,   acc = 0.191328
2025-06-18 10:38:46.349 | INFO     | model:train:239 - [epoch 5]: epoch loss = 2.198157,   acc = 0.188562
2025-06-18 10:38:56.390 | INFO     | model:train:239 - [epoch 6]: epoch loss = 2.098932,   acc = 0.191640
2025-06-18 10:39:06.807 | INFO     | model:train:239 - [epoch 7]: epoch loss = 1.913530,   acc = 0.293710
2025-06-18 10:39:17.392 | INFO     | model:train:239 - [epoch 8]: epoch loss = 1.763247,   acc = 0.398443
2025-06-18 10:39:27.934 | INFO     | model:train:239 - [epoch 9]: epoch loss = 1.632374,   acc = 0.484473
2025-06-18 10:39:38.506 | INFO     | model:train:239 - [epoch 10]: epoch loss = 1.537523,   acc = 0.538366
2025-06-18 10:39:49.123 | INFO     | model:train:239 - [epoch 11]: epoch loss = 1.495700,   acc = 0.544157
2025-06-18 10:39:59.880 | INFO     | model:train:239 - [epoch 12]: epoch loss = 1.396243,   acc = 0.582491
2025-06-18 10:40:10.524 | INFO     | model:train:239 - [epoch 13]: epoch loss = 1.333397,   acc = 0.615903
2025-06-18 10:40:21.153 | INFO     | model:train:239 - [epoch 14]: epoch loss = 1.285078,   acc = 0.632033
2025-06-18 10:40:32.004 | INFO     | model:train:239 - [epoch 15]: epoch loss = 1.224321,   acc = 0.662275
2025-06-18 10:40:42.928 | INFO     | model:train:239 - [epoch 16]: epoch loss = 1.171056,   acc = 0.678379
2025-06-18 10:40:53.253 | INFO     | model:train:239 - [epoch 17]: epoch loss = 1.130020,   acc = 0.695715
2025-06-18 10:41:04.111 | INFO     | model:train:239 - [epoch 18]: epoch loss = 1.110489,   acc = 0.701751
2025-06-18 10:41:14.721 | INFO     | model:train:239 - [epoch 19]: epoch loss = 1.060970,   acc = 0.711907
2025-06-18 10:41:25.486 | INFO     | model:train:239 - [epoch 20]: epoch loss = 0.999478,   acc = 0.735484
2025-06-18 10:41:25.817 | INFO     | model:train:255 - [epoch 20]: val loss = 2.300826,   val acc = 0.551693,   val balanced acc = 0.458792
2025-06-18 10:41:36.948 | INFO     | model:train:239 - [epoch 21]: epoch loss = 0.961120,   acc = 0.750240
2025-06-18 10:41:47.760 | INFO     | model:train:239 - [epoch 22]: epoch loss = 0.966634,   acc = 0.749505
2025-06-18 10:41:58.646 | INFO     | model:train:239 - [epoch 23]: epoch loss = 0.967852,   acc = 0.744831
2025-06-18 10:42:09.337 | INFO     | model:train:239 - [epoch 24]: epoch loss = 1.027966,   acc = 0.717049
2025-06-18 10:42:19.917 | INFO     | model:train:239 - [epoch 25]: epoch loss = 0.903853,   acc = 0.767533
2025-06-18 10:42:30.606 | INFO     | model:train:239 - [epoch 26]: epoch loss = 0.856677,   acc = 0.782218
2025-06-18 10:42:41.503 | INFO     | model:train:239 - [epoch 27]: epoch loss = 0.841703,   acc = 0.785598
2025-06-18 10:42:52.280 | INFO     | model:train:239 - [epoch 28]: epoch loss = 0.808710,   acc = 0.798882
2025-06-18 10:43:03.423 | INFO     | model:train:239 - [epoch 29]: epoch loss = 0.800039,   acc = 0.801569
2025-06-18 10:43:14.093 | INFO     | model:train:239 - [epoch 30]: epoch loss = 0.773339,   acc = 0.807432
2025-06-18 10:43:24.822 | INFO     | model:train:239 - [epoch 31]: epoch loss = 0.746235,   acc = 0.821143
2025-06-18 10:43:35.159 | INFO     | model:train:239 - [epoch 32]: epoch loss = 0.724723,   acc = 0.829624
2025-06-18 10:43:45.879 | INFO     | model:train:239 - [epoch 33]: epoch loss = 0.702150,   acc = 0.835177
2025-06-18 10:43:56.714 | INFO     | model:train:239 - [epoch 34]: epoch loss = 0.692303,   acc = 0.839473
2025-06-18 10:44:07.320 | INFO     | model:train:239 - [epoch 35]: epoch loss = 0.675964,   acc = 0.843317
2025-06-18 10:44:18.023 | INFO     | model:train:239 - [epoch 36]: epoch loss = 0.683011,   acc = 0.840976
2025-06-18 10:44:28.805 | INFO     | model:train:239 - [epoch 37]: epoch loss = 0.677667,   acc = 0.841082
2025-06-18 10:44:39.590 | INFO     | model:train:239 - [epoch 38]: epoch loss = 0.639147,   acc = 0.853074
2025-06-18 10:44:50.495 | INFO     | model:train:239 - [epoch 39]: epoch loss = 0.635739,   acc = 0.853414
2025-06-18 10:45:01.169 | INFO     | model:train:239 - [epoch 40]: epoch loss = 0.652626,   acc = 0.850312
2025-06-18 10:45:01.475 | INFO     | model:train:255 - [epoch 40]: val loss = 2.802893,   val acc = 0.550673,   val balanced acc = 0.477252
2025-06-18 10:45:12.344 | INFO     | model:train:239 - [epoch 41]: epoch loss = 0.638937,   acc = 0.853757
2025-06-18 10:45:23.125 | INFO     | model:train:239 - [epoch 42]: epoch loss = 0.622718,   acc = 0.856675
2025-06-18 10:45:33.882 | INFO     | model:train:239 - [epoch 43]: epoch loss = 0.588127,   acc = 0.868600
2025-06-18 10:45:44.397 | INFO     | model:train:239 - [epoch 44]: epoch loss = 0.614077,   acc = 0.861871
2025-06-18 10:45:55.210 | INFO     | model:train:239 - [epoch 45]: epoch loss = 0.573437,   acc = 0.873603
2025-06-18 10:46:05.819 | INFO     | model:train:239 - [epoch 46]: epoch loss = 0.546518,   acc = 0.883781
2025-06-18 10:46:16.738 | INFO     | model:train:239 - [epoch 47]: epoch loss = 0.524056,   acc = 0.890544
2025-06-18 10:46:27.517 | INFO     | model:train:239 - [epoch 48]: epoch loss = 0.509627,   acc = 0.896099
2025-06-18 10:46:38.194 | INFO     | model:train:239 - [epoch 49]: epoch loss = 0.494966,   acc = 0.899722
2025-06-18 10:46:48.686 | INFO     | model:train:239 - [epoch 50]: epoch loss = 0.492955,   acc = 0.899316
2025-06-18 10:46:59.423 | INFO     | model:train:239 - [epoch 51]: epoch loss = 0.487370,   acc = 0.901178
2025-06-18 10:47:09.646 | INFO     | model:train:239 - [epoch 52]: epoch loss = 0.482638,   acc = 0.904602
2025-06-18 10:47:20.483 | INFO     | model:train:239 - [epoch 53]: epoch loss = 0.464069,   acc = 0.908740
2025-06-18 10:47:30.949 | INFO     | model:train:239 - [epoch 54]: epoch loss = 0.461513,   acc = 0.908715
2025-06-18 10:47:41.745 | INFO     | model:train:239 - [epoch 55]: epoch loss = 0.458010,   acc = 0.910292
2025-06-18 10:47:52.579 | INFO     | model:train:239 - [epoch 56]: epoch loss = 0.457818,   acc = 0.907366
2025-06-18 10:48:03.316 | INFO     | model:train:239 - [epoch 57]: epoch loss = 0.458168,   acc = 0.908018
2025-06-18 10:48:14.253 | INFO     | model:train:239 - [epoch 58]: epoch loss = 0.439793,   acc = 0.912832
2025-06-18 10:48:25.116 | INFO     | model:train:239 - [epoch 59]: epoch loss = 0.436834,   acc = 0.915456
2025-06-18 10:48:36.167 | INFO     | model:train:239 - [epoch 60]: epoch loss = 0.426583,   acc = 0.918022
2025-06-18 10:48:36.499 | INFO     | model:train:255 - [epoch 60]: val loss = 2.587422,   val acc = 0.574670,   val balanced acc = 0.528772
2025-06-18 10:48:47.472 | INFO     | model:train:239 - [epoch 61]: epoch loss = 0.424311,   acc = 0.918071
2025-06-18 10:48:58.180 | INFO     | model:train:239 - [epoch 62]: epoch loss = 0.417918,   acc = 0.919201
2025-06-18 10:49:08.822 | INFO     | model:train:239 - [epoch 63]: epoch loss = 0.415273,   acc = 0.921080
2025-06-18 10:49:19.194 | INFO     | model:train:239 - [epoch 64]: epoch loss = 0.406502,   acc = 0.924694
2025-06-18 10:49:29.928 | INFO     | model:train:239 - [epoch 65]: epoch loss = 0.403618,   acc = 0.924025
2025-06-18 10:49:40.934 | INFO     | model:train:239 - [epoch 66]: epoch loss = 0.399853,   acc = 0.924128
2025-06-18 10:49:51.806 | INFO     | model:train:239 - [epoch 67]: epoch loss = 0.392708,   acc = 0.926479
2025-06-18 10:50:02.689 | INFO     | model:train:239 - [epoch 68]: epoch loss = 0.385524,   acc = 0.928963
2025-06-18 10:50:13.507 | INFO     | model:train:239 - [epoch 69]: epoch loss = 0.380842,   acc = 0.929723
2025-06-18 10:50:23.787 | INFO     | model:train:239 - [epoch 70]: epoch loss = 0.386510,   acc = 0.929748
2025-06-18 10:50:34.539 | INFO     | model:train:239 - [epoch 71]: epoch loss = 0.388649,   acc = 0.927017
2025-06-18 10:50:45.489 | INFO     | model:train:239 - [epoch 72]: epoch loss = 0.381268,   acc = 0.927850
2025-06-18 10:50:56.243 | INFO     | model:train:239 - [epoch 73]: epoch loss = 0.371655,   acc = 0.931211
2025-06-18 10:51:06.953 | INFO     | model:train:239 - [epoch 74]: epoch loss = 0.360052,   acc = 0.933494
2025-06-18 10:51:17.324 | INFO     | model:train:239 - [epoch 75]: epoch loss = 0.358391,   acc = 0.936284
2025-06-18 10:51:28.550 | INFO     | model:train:239 - [epoch 76]: epoch loss = 0.352964,   acc = 0.936771
2025-06-18 10:51:39.220 | INFO     | model:train:239 - [epoch 77]: epoch loss = 0.348941,   acc = 0.937828
2025-06-18 10:51:49.625 | INFO     | model:train:239 - [epoch 78]: epoch loss = 0.349659,   acc = 0.937954
2025-06-18 10:52:00.341 | INFO     | model:train:239 - [epoch 79]: epoch loss = 0.340705,   acc = 0.939923
2025-06-18 10:52:10.989 | INFO     | model:train:239 - [epoch 80]: epoch loss = 0.339796,   acc = 0.940308
2025-06-18 10:52:11.294 | INFO     | model:train:255 - [epoch 80]: val loss = 3.150009,   val acc = 0.557317,   val balanced acc = 0.513346
2025-06-18 10:52:11.382 | INFO     | model:train:275 - EarlyStopping counter: 1 out of 3
2025-06-18 10:52:22.372 | INFO     | model:train:239 - [epoch 81]: epoch loss = 0.328639,   acc = 0.942826
2025-06-18 10:52:33.102 | INFO     | model:train:239 - [epoch 82]: epoch loss = 0.332925,   acc = 0.942658
2025-06-18 10:52:43.911 | INFO     | model:train:239 - [epoch 83]: epoch loss = 0.332220,   acc = 0.942362
2025-06-18 10:52:54.399 | INFO     | model:train:239 - [epoch 84]: epoch loss = 0.332510,   acc = 0.942610
2025-06-18 10:53:05.571 | INFO     | model:train:239 - [epoch 85]: epoch loss = 0.325323,   acc = 0.942928
2025-06-18 10:53:16.659 | INFO     | model:train:239 - [epoch 86]: epoch loss = 0.322743,   acc = 0.943534
2025-06-18 10:53:27.648 | INFO     | model:train:239 - [epoch 87]: epoch loss = 0.321630,   acc = 0.943058
2025-06-18 10:53:38.449 | INFO     | model:train:239 - [epoch 88]: epoch loss = 0.322419,   acc = 0.943291
2025-06-18 10:53:49.216 | INFO     | model:train:239 - [epoch 89]: epoch loss = 0.319932,   acc = 0.943592
2025-06-18 10:54:00.301 | INFO     | model:train:239 - [epoch 90]: epoch loss = 0.311520,   acc = 0.946263
2025-06-18 10:54:11.273 | INFO     | model:train:239 - [epoch 91]: epoch loss = 0.311822,   acc = 0.946877
2025-06-18 10:54:22.197 | INFO     | model:train:239 - [epoch 92]: epoch loss = 0.308708,   acc = 0.947503
2025-06-18 10:54:33.098 | INFO     | model:train:239 - [epoch 93]: epoch loss = 0.307415,   acc = 0.947268
2025-06-18 10:54:44.111 | INFO     | model:train:239 - [epoch 94]: epoch loss = 0.305256,   acc = 0.947704
2025-06-18 10:54:54.928 | INFO     | model:train:239 - [epoch 95]: epoch loss = 0.304529,   acc = 0.948651
2025-06-18 10:55:05.695 | INFO     | model:train:239 - [epoch 96]: epoch loss = 0.301800,   acc = 0.949763
2025-06-18 10:55:16.559 | INFO     | model:train:239 - [epoch 97]: epoch loss = 0.298428,   acc = 0.949299
2025-06-18 10:55:27.251 | INFO     | model:train:239 - [epoch 98]: epoch loss = 0.298951,   acc = 0.948742
2025-06-18 10:55:37.870 | INFO     | model:train:239 - [epoch 99]: epoch loss = 0.296920,   acc = 0.950472
2025-06-18 10:55:48.307 | INFO     | model:train:239 - [epoch 100]: epoch loss = 0.290504,   acc = 0.951848
2025-06-18 10:55:48.617 | INFO     | model:train:255 - [epoch 100]: val loss = 3.050847,   val acc = 0.564846,   val balanced acc = 0.516853
2025-06-18 10:55:48.698 | INFO     | model:train:275 - EarlyStopping counter: 2 out of 3
2025-06-18 10:55:59.325 | INFO     | model:train:239 - [epoch 101]: epoch loss = 0.292290,   acc = 0.951469
2025-06-18 10:56:09.995 | INFO     | model:train:239 - [epoch 102]: epoch loss = 0.288955,   acc = 0.952180
2025-06-18 10:56:20.629 | INFO     | model:train:239 - [epoch 103]: epoch loss = 0.287153,   acc = 0.952766
2025-06-18 10:56:31.435 | INFO     | model:train:239 - [epoch 104]: epoch loss = 0.284405,   acc = 0.953110
2025-06-18 10:56:42.264 | INFO     | model:train:239 - [epoch 105]: epoch loss = 0.284400,   acc = 0.953682
2025-06-18 10:56:53.145 | INFO     | model:train:239 - [epoch 106]: epoch loss = 0.282588,   acc = 0.953956
2025-06-18 10:57:04.194 | INFO     | model:train:239 - [epoch 107]: epoch loss = 0.281921,   acc = 0.953803
2025-06-18 10:57:14.976 | INFO     | model:train:239 - [epoch 108]: epoch loss = 0.281882,   acc = 0.953765
2025-06-18 10:57:25.435 | INFO     | model:train:239 - [epoch 109]: epoch loss = 0.281186,   acc = 0.953603
2025-06-18 10:57:35.717 | INFO     | model:train:239 - [epoch 110]: epoch loss = 0.284121,   acc = 0.953595
2025-06-18 10:57:46.365 | INFO     | model:train:239 - [epoch 111]: epoch loss = 0.275449,   acc = 0.955111
2025-06-18 10:57:57.072 | INFO     | model:train:239 - [epoch 112]: epoch loss = 0.277118,   acc = 0.955486
2025-06-18 10:58:07.977 | INFO     | model:train:239 - [epoch 113]: epoch loss = 0.275289,   acc = 0.955222
2025-06-18 10:58:18.747 | INFO     | model:train:239 - [epoch 114]: epoch loss = 0.272734,   acc = 0.955761
2025-06-18 10:58:29.739 | INFO     | model:train:239 - [epoch 115]: epoch loss = 0.273172,   acc = 0.955105
2025-06-18 10:58:40.592 | INFO     | model:train:239 - [epoch 116]: epoch loss = 0.271063,   acc = 0.956023
2025-06-18 10:58:51.213 | INFO     | model:train:239 - [epoch 117]: epoch loss = 0.270477,   acc = 0.956977
2025-06-18 10:59:02.109 | INFO     | model:train:239 - [epoch 118]: epoch loss = 0.271482,   acc = 0.956565
2025-06-18 10:59:13.010 | INFO     | model:train:239 - [epoch 119]: epoch loss = 0.269973,   acc = 0.957140
2025-06-18 10:59:23.455 | INFO     | model:train:239 - [epoch 120]: epoch loss = 0.270392,   acc = 0.956928
2025-06-18 10:59:23.772 | INFO     | model:train:255 - [epoch 120]: val loss = 3.338592,   val acc = 0.556042,   val balanced acc = 0.510613
2025-06-18 10:59:23.825 | INFO     | model:train:275 - EarlyStopping counter: 3 out of 3
2025-06-18 10:59:23.825 | INFO     | model:train:277 - Early stopping triggered.
