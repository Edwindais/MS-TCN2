2025-06-09 09:25:48.219 | INFO     | model:train:237 - [epoch 1]: epoch loss = 2.588707,   acc = 0.147126
2025-06-09 09:25:53.520 | INFO     | model:train:237 - [epoch 2]: epoch loss = 2.500117,   acc = 0.161277
2025-06-09 09:25:58.833 | INFO     | model:train:237 - [epoch 3]: epoch loss = 2.459616,   acc = 0.166364
2025-06-09 09:26:04.163 | INFO     | model:train:237 - [epoch 4]: epoch loss = 2.426555,   acc = 0.183645
2025-06-09 09:26:09.456 | INFO     | model:train:237 - [epoch 5]: epoch loss = 2.377931,   acc = 0.177057
2025-06-09 09:26:14.855 | INFO     | model:train:237 - [epoch 6]: epoch loss = 2.348313,   acc = 0.180160
2025-06-09 09:26:20.407 | INFO     | model:train:237 - [epoch 7]: epoch loss = 2.256172,   acc = 0.186635
2025-06-09 09:26:25.880 | INFO     | model:train:237 - [epoch 8]: epoch loss = 2.215498,   acc = 0.192715
2025-06-09 09:26:31.298 | INFO     | model:train:237 - [epoch 9]: epoch loss = 2.074988,   acc = 0.219864
2025-06-09 09:26:36.618 | INFO     | model:train:237 - [epoch 10]: epoch loss = 2.007578,   acc = 0.278626
2025-06-09 09:26:42.143 | INFO     | model:train:237 - [epoch 11]: epoch loss = 1.958070,   acc = 0.346536
2025-06-09 09:26:47.459 | INFO     | model:train:237 - [epoch 12]: epoch loss = 1.798724,   acc = 0.407319
2025-06-09 09:26:52.939 | INFO     | model:train:237 - [epoch 13]: epoch loss = 1.784059,   acc = 0.476069
2025-06-09 09:26:58.436 | INFO     | model:train:237 - [epoch 14]: epoch loss = 1.749309,   acc = 0.459884
2025-06-09 09:27:03.869 | INFO     | model:train:237 - [epoch 15]: epoch loss = 1.600787,   acc = 0.548018
2025-06-09 09:27:09.146 | INFO     | model:train:237 - [epoch 16]: epoch loss = 1.489054,   acc = 0.575297
2025-06-09 09:27:14.459 | INFO     | model:train:237 - [epoch 17]: epoch loss = 1.408199,   acc = 0.612856
2025-06-09 09:27:19.978 | INFO     | model:train:237 - [epoch 18]: epoch loss = 1.440020,   acc = 0.617558
2025-06-09 09:27:25.397 | INFO     | model:train:237 - [epoch 19]: epoch loss = 1.461999,   acc = 0.590914
2025-06-09 09:27:31.044 | INFO     | model:train:237 - [epoch 20]: epoch loss = 1.372671,   acc = 0.623852
2025-06-09 09:27:31.373 | INFO     | model:train:245 - [epoch 20]: val loss = 2.271108,   val acc = 0.539124,   val balanced acc = 0.446804
2025-06-09 09:27:36.842 | INFO     | model:train:237 - [epoch 21]: epoch loss = 1.302257,   acc = 0.650721
2025-06-09 09:27:42.245 | INFO     | model:train:237 - [epoch 22]: epoch loss = 1.229131,   acc = 0.661889
2025-06-09 09:27:47.607 | INFO     | model:train:237 - [epoch 23]: epoch loss = 1.189469,   acc = 0.682220
2025-06-09 09:27:52.907 | INFO     | model:train:237 - [epoch 24]: epoch loss = 1.175831,   acc = 0.684516
2025-06-09 09:27:58.196 | INFO     | model:train:237 - [epoch 25]: epoch loss = 1.184193,   acc = 0.699261
2025-06-09 09:28:03.613 | INFO     | model:train:237 - [epoch 26]: epoch loss = 1.180935,   acc = 0.678107
2025-06-09 09:28:08.961 | INFO     | model:train:237 - [epoch 27]: epoch loss = 1.092855,   acc = 0.714304
2025-06-09 09:28:14.372 | INFO     | model:train:237 - [epoch 28]: epoch loss = 1.086899,   acc = 0.716388
2025-06-09 09:28:19.806 | INFO     | model:train:237 - [epoch 29]: epoch loss = 1.117911,   acc = 0.730335
2025-06-09 09:28:25.080 | INFO     | model:train:237 - [epoch 30]: epoch loss = 1.059874,   acc = 0.724816
2025-06-09 09:28:30.275 | INFO     | model:train:237 - [epoch 31]: epoch loss = 1.034023,   acc = 0.729365
2025-06-09 09:28:35.659 | INFO     | model:train:237 - [epoch 32]: epoch loss = 0.992839,   acc = 0.751947
2025-06-09 09:28:41.120 | INFO     | model:train:237 - [epoch 33]: epoch loss = 0.966164,   acc = 0.768227
2025-06-09 09:28:46.647 | INFO     | model:train:237 - [epoch 34]: epoch loss = 0.930230,   acc = 0.774828
2025-06-09 09:28:52.216 | INFO     | model:train:237 - [epoch 35]: epoch loss = 1.393754,   acc = 0.627395
2025-06-09 09:28:57.805 | INFO     | model:train:237 - [epoch 36]: epoch loss = 1.175461,   acc = 0.694275
2025-06-09 09:29:03.413 | INFO     | model:train:237 - [epoch 37]: epoch loss = 1.033843,   acc = 0.733373
2025-06-09 09:29:08.858 | INFO     | model:train:237 - [epoch 38]: epoch loss = 0.937761,   acc = 0.767935
2025-06-09 09:29:14.399 | INFO     | model:train:237 - [epoch 39]: epoch loss = 0.893068,   acc = 0.778667
2025-06-09 09:29:19.849 | INFO     | model:train:237 - [epoch 40]: epoch loss = 0.865063,   acc = 0.796174
2025-06-09 09:29:20.158 | INFO     | model:train:245 - [epoch 40]: val loss = 2.053012,   val acc = 0.570696,   val balanced acc = 0.486716
2025-06-09 09:29:25.613 | INFO     | model:train:237 - [epoch 41]: epoch loss = 0.840295,   acc = 0.805264
2025-06-09 09:29:31.006 | INFO     | model:train:237 - [epoch 42]: epoch loss = 0.823232,   acc = 0.808238
2025-06-09 09:29:35.984 | INFO     | model:train:237 - [epoch 43]: epoch loss = 0.826353,   acc = 0.814773
2025-06-09 09:29:41.326 | INFO     | model:train:237 - [epoch 44]: epoch loss = 0.922778,   acc = 0.776479
2025-06-09 09:29:46.772 | INFO     | model:train:237 - [epoch 45]: epoch loss = 0.869834,   acc = 0.793383
2025-06-09 09:29:52.434 | INFO     | model:train:237 - [epoch 46]: epoch loss = 0.814456,   acc = 0.807077
2025-06-09 09:29:57.820 | INFO     | model:train:237 - [epoch 47]: epoch loss = 0.772850,   acc = 0.823772
2025-06-09 09:30:03.239 | INFO     | model:train:237 - [epoch 48]: epoch loss = 0.738712,   acc = 0.839141
2025-06-09 09:30:08.736 | INFO     | model:train:237 - [epoch 49]: epoch loss = 0.716128,   acc = 0.842974
2025-06-09 09:30:14.140 | INFO     | model:train:237 - [epoch 50]: epoch loss = 0.701059,   acc = 0.848497
2025-06-09 09:30:19.694 | INFO     | model:train:237 - [epoch 51]: epoch loss = 0.688281,   acc = 0.848959
2025-06-09 09:30:25.145 | INFO     | model:train:237 - [epoch 52]: epoch loss = 0.675976,   acc = 0.855187
2025-06-09 09:30:30.368 | INFO     | model:train:237 - [epoch 53]: epoch loss = 0.684369,   acc = 0.855250
2025-06-09 09:30:35.982 | INFO     | model:train:237 - [epoch 54]: epoch loss = 0.675065,   acc = 0.859139
2025-06-09 09:30:41.342 | INFO     | model:train:237 - [epoch 55]: epoch loss = 0.655909,   acc = 0.863636
2025-06-09 09:30:46.733 | INFO     | model:train:237 - [epoch 56]: epoch loss = 0.634195,   acc = 0.866042
2025-06-09 09:30:52.274 | INFO     | model:train:237 - [epoch 57]: epoch loss = 0.616322,   acc = 0.873487
2025-06-09 09:30:57.764 | INFO     | model:train:237 - [epoch 58]: epoch loss = 0.602258,   acc = 0.875652
2025-06-09 09:31:03.103 | INFO     | model:train:237 - [epoch 59]: epoch loss = 0.593234,   acc = 0.880057
2025-06-09 09:31:08.407 | INFO     | model:train:237 - [epoch 60]: epoch loss = 0.573642,   acc = 0.884897
2025-06-09 09:31:08.704 | INFO     | model:train:245 - [epoch 60]: val loss = 2.676269,   val acc = 0.561397,   val balanced acc = 0.492782
2025-06-09 09:31:14.076 | INFO     | model:train:237 - [epoch 61]: epoch loss = 0.571656,   acc = 0.886599
2025-06-09 09:31:19.826 | INFO     | model:train:237 - [epoch 62]: epoch loss = 0.554454,   acc = 0.891847
2025-06-09 09:31:25.033 | INFO     | model:train:237 - [epoch 63]: epoch loss = 0.553677,   acc = 0.894092
2025-06-09 09:31:30.638 | INFO     | model:train:237 - [epoch 64]: epoch loss = 0.538415,   acc = 0.894769
2025-06-09 09:31:36.066 | INFO     | model:train:237 - [epoch 65]: epoch loss = 0.523778,   acc = 0.898502
2025-06-09 09:31:41.437 | INFO     | model:train:237 - [epoch 66]: epoch loss = 0.523714,   acc = 0.901449
2025-06-09 09:31:46.962 | INFO     | model:train:237 - [epoch 67]: epoch loss = 0.529317,   acc = 0.900718
2025-06-09 09:31:52.480 | INFO     | model:train:237 - [epoch 68]: epoch loss = 0.523165,   acc = 0.901520
2025-06-09 09:31:57.931 | INFO     | model:train:237 - [epoch 69]: epoch loss = 0.506841,   acc = 0.905293
2025-06-09 09:32:03.429 | INFO     | model:train:237 - [epoch 70]: epoch loss = 0.516803,   acc = 0.903103
2025-06-09 09:32:08.626 | INFO     | model:train:237 - [epoch 71]: epoch loss = 0.500634,   acc = 0.908404
2025-06-09 09:32:13.972 | INFO     | model:train:237 - [epoch 72]: epoch loss = 0.485863,   acc = 0.910714
2025-06-09 09:32:19.879 | INFO     | model:train:237 - [epoch 73]: epoch loss = 0.470002,   acc = 0.913818
2025-06-09 09:32:25.294 | INFO     | model:train:237 - [epoch 74]: epoch loss = 0.463946,   acc = 0.918054
2025-06-09 09:32:30.698 | INFO     | model:train:237 - [epoch 75]: epoch loss = 0.459332,   acc = 0.917765
2025-06-09 09:32:36.181 | INFO     | model:train:237 - [epoch 76]: epoch loss = 0.461798,   acc = 0.919248
2025-06-09 09:32:41.607 | INFO     | model:train:237 - [epoch 77]: epoch loss = 0.447799,   acc = 0.923284
2025-06-09 09:32:46.699 | INFO     | model:train:237 - [epoch 78]: epoch loss = 0.448038,   acc = 0.923360
2025-06-09 09:32:52.135 | INFO     | model:train:237 - [epoch 79]: epoch loss = 0.437173,   acc = 0.924340
2025-06-09 09:32:57.508 | INFO     | model:train:237 - [epoch 80]: epoch loss = 0.455017,   acc = 0.920931
2025-06-09 09:32:57.819 | INFO     | model:train:245 - [epoch 80]: val loss = 2.676155,   val acc = 0.567096,   val balanced acc = 0.494753
2025-06-09 09:33:02.848 | INFO     | model:train:237 - [epoch 81]: epoch loss = 0.448543,   acc = 0.922748
2025-06-09 09:33:08.692 | INFO     | model:train:237 - [epoch 82]: epoch loss = 0.435812,   acc = 0.925192
2025-06-09 09:33:14.020 | INFO     | model:train:237 - [epoch 83]: epoch loss = 0.438391,   acc = 0.923815
2025-06-09 09:33:19.320 | INFO     | model:train:237 - [epoch 84]: epoch loss = 0.434085,   acc = 0.926527
2025-06-09 09:33:24.620 | INFO     | model:train:237 - [epoch 85]: epoch loss = 0.437492,   acc = 0.926777
2025-06-09 09:33:29.949 | INFO     | model:train:237 - [epoch 86]: epoch loss = 0.418545,   acc = 0.929783
2025-06-09 09:33:35.316 | INFO     | model:train:237 - [epoch 87]: epoch loss = 0.419511,   acc = 0.930766
2025-06-09 09:33:40.701 | INFO     | model:train:237 - [epoch 88]: epoch loss = 0.408057,   acc = 0.932424
2025-06-09 09:33:46.062 | INFO     | model:train:237 - [epoch 89]: epoch loss = 0.404567,   acc = 0.934279
2025-06-09 09:33:51.515 | INFO     | model:train:237 - [epoch 90]: epoch loss = 0.402139,   acc = 0.934980
2025-06-09 09:33:57.050 | INFO     | model:train:237 - [epoch 91]: epoch loss = 0.400689,   acc = 0.935134
2025-06-09 09:34:02.416 | INFO     | model:train:237 - [epoch 92]: epoch loss = 0.394445,   acc = 0.937729
2025-06-09 09:34:07.776 | INFO     | model:train:237 - [epoch 93]: epoch loss = 0.392246,   acc = 0.938091
2025-06-09 09:34:13.306 | INFO     | model:train:237 - [epoch 94]: epoch loss = 0.383158,   acc = 0.939278
2025-06-09 09:34:18.920 | INFO     | model:train:237 - [epoch 95]: epoch loss = 0.372223,   acc = 0.941076
2025-06-09 09:34:24.462 | INFO     | model:train:237 - [epoch 96]: epoch loss = 0.370541,   acc = 0.941978
2025-06-09 09:34:29.387 | INFO     | model:train:237 - [epoch 97]: epoch loss = 0.385793,   acc = 0.940762
2025-06-09 09:34:34.739 | INFO     | model:train:237 - [epoch 98]: epoch loss = 0.372501,   acc = 0.941883
2025-06-09 09:34:40.138 | INFO     | model:train:237 - [epoch 99]: epoch loss = 0.367960,   acc = 0.943700
2025-06-09 09:34:45.629 | INFO     | model:train:237 - [epoch 100]: epoch loss = 0.364265,   acc = 0.943432
2025-06-09 09:34:45.936 | INFO     | model:train:245 - [epoch 100]: val loss = 2.838834,   val acc = 0.567321,   val balanced acc = 0.489359
2025-06-09 09:34:45.991 | INFO     | model:train:258 - EarlyStopping counter: 1 out of 3
2025-06-09 09:34:51.475 | INFO     | model:train:237 - [epoch 101]: epoch loss = 0.363232,   acc = 0.944991
2025-06-09 09:34:56.886 | INFO     | model:train:237 - [epoch 102]: epoch loss = 0.365324,   acc = 0.944991
2025-06-09 09:35:02.559 | INFO     | model:train:237 - [epoch 103]: epoch loss = 0.363333,   acc = 0.945441
2025-06-09 09:35:07.940 | INFO     | model:train:237 - [epoch 104]: epoch loss = 0.356215,   acc = 0.944956
2025-06-09 09:35:13.318 | INFO     | model:train:237 - [epoch 105]: epoch loss = 0.355759,   acc = 0.945797
2025-06-09 09:35:19.412 | INFO     | model:train:237 - [epoch 106]: epoch loss = 0.351277,   acc = 0.946678
2025-06-09 09:35:24.740 | INFO     | model:train:237 - [epoch 107]: epoch loss = 0.349456,   acc = 0.947117
2025-06-09 09:35:29.963 | INFO     | model:train:237 - [epoch 108]: epoch loss = 0.352354,   acc = 0.947575
2025-06-09 09:35:36.126 | INFO     | model:train:237 - [epoch 109]: epoch loss = 0.348109,   acc = 0.948480
2025-06-09 09:35:41.561 | INFO     | model:train:237 - [epoch 110]: epoch loss = 0.356131,   acc = 0.948961
2025-06-09 09:35:47.408 | INFO     | model:train:237 - [epoch 111]: epoch loss = 0.345008,   acc = 0.949747
2025-06-09 09:35:53.112 | INFO     | model:train:237 - [epoch 112]: epoch loss = 0.340390,   acc = 0.949179
2025-06-09 09:35:58.897 | INFO     | model:train:237 - [epoch 113]: epoch loss = 0.337645,   acc = 0.949454
2025-06-09 09:36:04.841 | INFO     | model:train:237 - [epoch 114]: epoch loss = 0.342842,   acc = 0.949836
2025-06-09 09:36:10.939 | INFO     | model:train:237 - [epoch 115]: epoch loss = 0.339048,   acc = 0.950236
2025-06-09 09:36:16.360 | INFO     | model:train:237 - [epoch 116]: epoch loss = 0.341625,   acc = 0.950289
2025-06-09 09:36:21.866 | INFO     | model:train:237 - [epoch 117]: epoch loss = 0.334244,   acc = 0.951340
2025-06-09 09:36:27.306 | INFO     | model:train:237 - [epoch 118]: epoch loss = 0.336672,   acc = 0.951286
2025-06-09 09:36:32.420 | INFO     | model:train:237 - [epoch 119]: epoch loss = 0.333103,   acc = 0.952181
2025-06-09 09:36:37.897 | INFO     | model:train:237 - [epoch 120]: epoch loss = 0.333939,   acc = 0.951877
2025-06-09 09:36:38.232 | INFO     | model:train:245 - [epoch 120]: val loss = 3.400812,   val acc = 0.555067,   val balanced acc = 0.482129
2025-06-09 09:36:38.286 | INFO     | model:train:258 - EarlyStopping counter: 2 out of 3
2025-06-09 09:36:43.716 | INFO     | model:train:237 - [epoch 121]: epoch loss = 0.331100,   acc = 0.952011
2025-06-09 09:36:49.195 | INFO     | model:train:237 - [epoch 122]: epoch loss = 0.330377,   acc = 0.952030
2025-06-09 09:36:54.685 | INFO     | model:train:237 - [epoch 123]: epoch loss = 0.330043,   acc = 0.952911
2025-06-09 09:37:00.074 | INFO     | model:train:237 - [epoch 124]: epoch loss = 0.329816,   acc = 0.953537
2025-06-09 09:37:05.454 | INFO     | model:train:237 - [epoch 125]: epoch loss = 0.328913,   acc = 0.952729
2025-06-09 09:37:10.836 | INFO     | model:train:237 - [epoch 126]: epoch loss = 0.336663,   acc = 0.952978
2025-06-09 09:37:16.305 | INFO     | model:train:237 - [epoch 127]: epoch loss = 0.324729,   acc = 0.953934
2025-06-09 09:37:21.918 | INFO     | model:train:237 - [epoch 128]: epoch loss = 0.331652,   acc = 0.954193
2025-06-09 09:37:27.531 | INFO     | model:train:237 - [epoch 129]: epoch loss = 0.322282,   acc = 0.954371
2025-06-09 09:37:33.101 | INFO     | model:train:237 - [epoch 130]: epoch loss = 0.327470,   acc = 0.953745
2025-06-09 09:37:38.605 | INFO     | model:train:237 - [epoch 131]: epoch loss = 0.323686,   acc = 0.953967
2025-06-09 09:37:44.041 | INFO     | model:train:237 - [epoch 132]: epoch loss = 0.325652,   acc = 0.954477
2025-06-09 09:37:49.386 | INFO     | model:train:237 - [epoch 133]: epoch loss = 0.326583,   acc = 0.955076
2025-06-09 09:37:54.919 | INFO     | model:train:237 - [epoch 134]: epoch loss = 0.320051,   acc = 0.954987
2025-06-09 09:38:00.446 | INFO     | model:train:237 - [epoch 135]: epoch loss = 0.324295,   acc = 0.954771
2025-06-09 09:38:05.976 | INFO     | model:train:237 - [epoch 136]: epoch loss = 0.321348,   acc = 0.954724
2025-06-09 09:38:11.751 | INFO     | model:train:237 - [epoch 137]: epoch loss = 0.317123,   acc = 0.955422
2025-06-09 09:38:17.559 | INFO     | model:train:237 - [epoch 138]: epoch loss = 0.320506,   acc = 0.955226
2025-06-09 09:38:23.060 | INFO     | model:train:237 - [epoch 139]: epoch loss = 0.320441,   acc = 0.955817
2025-06-09 09:38:28.752 | INFO     | model:train:237 - [epoch 140]: epoch loss = 0.319777,   acc = 0.955437
2025-06-09 09:38:29.108 | INFO     | model:train:245 - [epoch 140]: val loss = 3.047557,   val acc = 0.553477,   val balanced acc = 0.479091
2025-06-09 09:38:29.145 | INFO     | model:train:258 - EarlyStopping counter: 3 out of 3
2025-06-09 09:38:29.145 | INFO     | model:train:260 - Early stopping triggered.
