2025-06-08 22:06:09.920 | INFO     | model:train:237 - [epoch 1]: epoch loss = 2.430078,   acc = 0.161518
2025-06-08 22:06:19.611 | INFO     | model:train:237 - [epoch 2]: epoch loss = 2.316479,   acc = 0.176416
2025-06-08 22:06:29.507 | INFO     | model:train:237 - [epoch 3]: epoch loss = 2.198562,   acc = 0.190580
2025-06-08 22:06:39.413 | INFO     | model:train:237 - [epoch 4]: epoch loss = 2.035031,   acc = 0.235685
2025-06-08 22:06:48.986 | INFO     | model:train:237 - [epoch 5]: epoch loss = 1.894418,   acc = 0.307268
2025-06-08 22:06:58.489 | INFO     | model:train:237 - [epoch 6]: epoch loss = 1.683590,   acc = 0.408271
2025-06-08 22:07:08.237 | INFO     | model:train:237 - [epoch 7]: epoch loss = 1.497241,   acc = 0.528329
2025-06-08 22:07:18.314 | INFO     | model:train:237 - [epoch 8]: epoch loss = 1.416905,   acc = 0.569986
2025-06-08 22:07:28.088 | INFO     | model:train:237 - [epoch 9]: epoch loss = 1.320598,   acc = 0.609033
2025-06-08 22:07:37.854 | INFO     | model:train:237 - [epoch 10]: epoch loss = 1.399582,   acc = 0.595194
2025-06-08 22:07:47.852 | INFO     | model:train:237 - [epoch 11]: epoch loss = 1.210220,   acc = 0.651574
2025-06-08 22:07:57.884 | INFO     | model:train:237 - [epoch 12]: epoch loss = 1.138045,   acc = 0.674682
2025-06-08 22:08:07.827 | INFO     | model:train:237 - [epoch 13]: epoch loss = 1.067258,   acc = 0.695134
2025-06-08 22:08:17.431 | INFO     | model:train:237 - [epoch 14]: epoch loss = 1.063471,   acc = 0.704753
2025-06-08 22:08:27.411 | INFO     | model:train:237 - [epoch 15]: epoch loss = 1.040455,   acc = 0.713522
2025-06-08 22:08:37.487 | INFO     | model:train:237 - [epoch 16]: epoch loss = 0.967307,   acc = 0.739020
2025-06-08 22:08:47.272 | INFO     | model:train:237 - [epoch 17]: epoch loss = 0.917932,   acc = 0.757687
2025-06-08 22:08:56.920 | INFO     | model:train:237 - [epoch 18]: epoch loss = 0.971236,   acc = 0.739152
2025-06-08 22:09:06.698 | INFO     | model:train:237 - [epoch 19]: epoch loss = 0.908225,   acc = 0.756101
2025-06-08 22:09:16.335 | INFO     | model:train:237 - [epoch 20]: epoch loss = 0.843339,   acc = 0.783700
2025-06-08 22:09:16.775 | INFO     | model:train:245 - [epoch 20]: val loss = 2.794534,   val acc = 0.457887,   val balanced acc = 0.510262
2025-06-08 22:09:26.596 | INFO     | model:train:237 - [epoch 21]: epoch loss = 0.786391,   acc = 0.801392
2025-06-08 22:09:36.230 | INFO     | model:train:237 - [epoch 22]: epoch loss = 0.736951,   acc = 0.815476
2025-06-08 22:09:45.806 | INFO     | model:train:237 - [epoch 23]: epoch loss = 0.731739,   acc = 0.818791
2025-06-08 22:09:55.279 | INFO     | model:train:237 - [epoch 24]: epoch loss = 0.718524,   acc = 0.823787
2025-06-08 22:10:04.812 | INFO     | model:train:237 - [epoch 25]: epoch loss = 0.698482,   acc = 0.828804
2025-06-08 22:10:14.473 | INFO     | model:train:237 - [epoch 26]: epoch loss = 0.699370,   acc = 0.828435
2025-06-08 22:10:24.379 | INFO     | model:train:237 - [epoch 27]: epoch loss = 0.692344,   acc = 0.831319
2025-06-08 22:10:33.929 | INFO     | model:train:237 - [epoch 28]: epoch loss = 0.670173,   acc = 0.841173
2025-06-08 22:10:43.835 | INFO     | model:train:237 - [epoch 29]: epoch loss = 0.623782,   acc = 0.857134
2025-06-08 22:10:53.443 | INFO     | model:train:237 - [epoch 30]: epoch loss = 0.592602,   acc = 0.868012
2025-06-08 22:11:03.252 | INFO     | model:train:237 - [epoch 31]: epoch loss = 0.569310,   acc = 0.875609
2025-06-08 22:11:12.750 | INFO     | model:train:237 - [epoch 32]: epoch loss = 0.580948,   acc = 0.874516
2025-06-08 22:11:22.389 | INFO     | model:train:237 - [epoch 33]: epoch loss = 0.596506,   acc = 0.861029
2025-06-08 22:11:31.954 | INFO     | model:train:237 - [epoch 34]: epoch loss = 0.543714,   acc = 0.879391
2025-06-08 22:11:41.539 | INFO     | model:train:237 - [epoch 35]: epoch loss = 0.538915,   acc = 0.880694
2025-06-08 22:11:51.260 | INFO     | model:train:237 - [epoch 36]: epoch loss = 0.502492,   acc = 0.892254
2025-06-08 22:12:01.097 | INFO     | model:train:237 - [epoch 37]: epoch loss = 0.487229,   acc = 0.897877
2025-06-08 22:12:11.132 | INFO     | model:train:237 - [epoch 38]: epoch loss = 0.482758,   acc = 0.896466
2025-06-08 22:12:20.924 | INFO     | model:train:237 - [epoch 39]: epoch loss = 0.470191,   acc = 0.902918
2025-06-08 22:12:30.447 | INFO     | model:train:237 - [epoch 40]: epoch loss = 0.451742,   acc = 0.909331
2025-06-08 22:12:30.874 | INFO     | model:train:245 - [epoch 40]: val loss = 3.230106,   val acc = 0.476626,   val balanced acc = 0.520885
2025-06-08 22:12:40.826 | INFO     | model:train:237 - [epoch 41]: epoch loss = 0.436096,   acc = 0.913377
2025-06-08 22:12:50.619 | INFO     | model:train:237 - [epoch 42]: epoch loss = 0.433953,   acc = 0.914521
2025-06-08 22:13:00.311 | INFO     | model:train:237 - [epoch 43]: epoch loss = 0.420317,   acc = 0.917145
2025-06-08 22:13:10.228 | INFO     | model:train:237 - [epoch 44]: epoch loss = 0.414048,   acc = 0.917656
2025-06-08 22:13:20.191 | INFO     | model:train:237 - [epoch 45]: epoch loss = 0.409328,   acc = 0.918787
2025-06-08 22:13:30.189 | INFO     | model:train:237 - [epoch 46]: epoch loss = 0.393488,   acc = 0.923757
2025-06-08 22:13:39.968 | INFO     | model:train:237 - [epoch 47]: epoch loss = 0.380770,   acc = 0.928577
2025-06-08 22:13:49.858 | INFO     | model:train:237 - [epoch 48]: epoch loss = 0.428965,   acc = 0.911282
2025-06-08 22:13:59.838 | INFO     | model:train:237 - [epoch 49]: epoch loss = 0.523515,   acc = 0.876953
2025-06-08 22:14:09.823 | INFO     | model:train:237 - [epoch 50]: epoch loss = 0.577870,   acc = 0.863133
2025-06-08 22:14:19.709 | INFO     | model:train:237 - [epoch 51]: epoch loss = 0.560787,   acc = 0.868186
2025-06-08 22:14:29.508 | INFO     | model:train:237 - [epoch 52]: epoch loss = 0.527701,   acc = 0.877677
2025-06-08 22:14:39.478 | INFO     | model:train:237 - [epoch 53]: epoch loss = 0.428892,   acc = 0.908877
2025-06-08 22:14:49.324 | INFO     | model:train:237 - [epoch 54]: epoch loss = 0.380200,   acc = 0.925815
2025-06-08 22:14:59.172 | INFO     | model:train:237 - [epoch 55]: epoch loss = 0.362570,   acc = 0.931986
2025-06-08 22:15:08.775 | INFO     | model:train:237 - [epoch 56]: epoch loss = 0.352289,   acc = 0.935443
2025-06-08 22:15:18.846 | INFO     | model:train:237 - [epoch 57]: epoch loss = 0.339941,   acc = 0.938745
2025-06-08 22:15:28.868 | INFO     | model:train:237 - [epoch 58]: epoch loss = 0.329714,   acc = 0.940397
2025-06-08 22:15:39.075 | INFO     | model:train:237 - [epoch 59]: epoch loss = 0.326967,   acc = 0.941918
2025-06-08 22:15:48.890 | INFO     | model:train:237 - [epoch 60]: epoch loss = 0.324881,   acc = 0.941691
2025-06-08 22:15:49.328 | INFO     | model:train:245 - [epoch 60]: val loss = 3.512237,   val acc = 0.477293,   val balanced acc = 0.526478
2025-06-08 22:15:59.226 | INFO     | model:train:237 - [epoch 61]: epoch loss = 0.320999,   acc = 0.943877
2025-06-08 22:16:08.941 | INFO     | model:train:237 - [epoch 62]: epoch loss = 0.313929,   acc = 0.944546
2025-06-08 22:16:18.773 | INFO     | model:train:237 - [epoch 63]: epoch loss = 0.306390,   acc = 0.946580
2025-06-08 22:16:28.488 | INFO     | model:train:237 - [epoch 64]: epoch loss = 0.307093,   acc = 0.945821
2025-06-08 22:16:38.299 | INFO     | model:train:237 - [epoch 65]: epoch loss = 0.299669,   acc = 0.947453
2025-06-08 22:16:47.924 | INFO     | model:train:237 - [epoch 66]: epoch loss = 0.297623,   acc = 0.948419
2025-06-08 22:16:57.733 | INFO     | model:train:237 - [epoch 67]: epoch loss = 0.290355,   acc = 0.950007
2025-06-08 22:17:07.207 | INFO     | model:train:237 - [epoch 68]: epoch loss = 0.291517,   acc = 0.950748
2025-06-08 22:17:16.871 | INFO     | model:train:237 - [epoch 69]: epoch loss = 0.285882,   acc = 0.952319
2025-06-08 22:17:26.364 | INFO     | model:train:237 - [epoch 70]: epoch loss = 0.284518,   acc = 0.952319
2025-06-08 22:17:36.195 | INFO     | model:train:237 - [epoch 71]: epoch loss = 0.280974,   acc = 0.951318
2025-06-08 22:17:46.032 | INFO     | model:train:237 - [epoch 72]: epoch loss = 0.276526,   acc = 0.952847
2025-06-08 22:17:55.861 | INFO     | model:train:237 - [epoch 73]: epoch loss = 0.273038,   acc = 0.953157
2025-06-08 22:18:05.629 | INFO     | model:train:237 - [epoch 74]: epoch loss = 0.269882,   acc = 0.954538
2025-06-08 22:18:15.538 | INFO     | model:train:237 - [epoch 75]: epoch loss = 0.268939,   acc = 0.954964
2025-06-08 22:18:25.220 | INFO     | model:train:237 - [epoch 76]: epoch loss = 0.266015,   acc = 0.955813
2025-06-08 22:18:34.871 | INFO     | model:train:237 - [epoch 77]: epoch loss = 0.263806,   acc = 0.956278
2025-06-08 22:18:44.655 | INFO     | model:train:237 - [epoch 78]: epoch loss = 0.256619,   acc = 0.958463
2025-06-08 22:18:54.318 | INFO     | model:train:237 - [epoch 79]: epoch loss = 0.256894,   acc = 0.957921
2025-06-08 22:19:04.076 | INFO     | model:train:237 - [epoch 80]: epoch loss = 0.251419,   acc = 0.958690
2025-06-08 22:19:04.540 | INFO     | model:train:245 - [epoch 80]: val loss = 3.171517,   val acc = 0.480427,   val balanced acc = 0.520868
2025-06-08 22:19:04.579 | INFO     | model:train:258 - EarlyStopping counter: 1 out of 3
2025-06-08 22:19:14.512 | INFO     | model:train:237 - [epoch 81]: epoch loss = 0.251019,   acc = 0.958643
2025-06-08 22:19:24.290 | INFO     | model:train:237 - [epoch 82]: epoch loss = 0.252930,   acc = 0.957602
2025-06-08 22:19:34.157 | INFO     | model:train:237 - [epoch 83]: epoch loss = 0.248975,   acc = 0.958662
2025-06-08 22:19:43.683 | INFO     | model:train:237 - [epoch 84]: epoch loss = 0.247963,   acc = 0.959266
2025-06-08 22:19:53.316 | INFO     | model:train:237 - [epoch 85]: epoch loss = 0.246869,   acc = 0.959833
2025-06-08 22:20:02.939 | INFO     | model:train:237 - [epoch 86]: epoch loss = 0.241927,   acc = 0.960245
2025-06-08 22:20:12.696 | INFO     | model:train:237 - [epoch 87]: epoch loss = 0.240320,   acc = 0.960129
2025-06-08 22:20:22.328 | INFO     | model:train:237 - [epoch 88]: epoch loss = 0.242169,   acc = 0.960567
2025-06-08 22:20:32.073 | INFO     | model:train:237 - [epoch 89]: epoch loss = 0.233262,   acc = 0.962917
2025-06-08 22:20:41.752 | INFO     | model:train:237 - [epoch 90]: epoch loss = 0.231659,   acc = 0.962883
2025-06-08 22:20:51.485 | INFO     | model:train:237 - [epoch 91]: epoch loss = 0.231099,   acc = 0.962848
2025-06-08 22:21:01.077 | INFO     | model:train:237 - [epoch 92]: epoch loss = 0.227225,   acc = 0.963807
2025-06-08 22:21:10.784 | INFO     | model:train:237 - [epoch 93]: epoch loss = 0.226543,   acc = 0.964346
2025-06-08 22:21:20.411 | INFO     | model:train:237 - [epoch 94]: epoch loss = 0.226916,   acc = 0.963876
2025-06-08 22:21:30.230 | INFO     | model:train:237 - [epoch 95]: epoch loss = 0.220635,   acc = 0.964845
2025-06-08 22:21:39.836 | INFO     | model:train:237 - [epoch 96]: epoch loss = 0.225696,   acc = 0.965053
2025-06-08 22:21:49.573 | INFO     | model:train:237 - [epoch 97]: epoch loss = 0.225172,   acc = 0.964018
2025-06-08 22:21:59.362 | INFO     | model:train:237 - [epoch 98]: epoch loss = 0.216241,   acc = 0.965745
2025-06-08 22:22:09.064 | INFO     | model:train:237 - [epoch 99]: epoch loss = 0.217174,   acc = 0.966485
2025-06-08 22:22:18.934 | INFO     | model:train:237 - [epoch 100]: epoch loss = 0.214131,   acc = 0.966905
2025-06-08 22:22:19.352 | INFO     | model:train:245 - [epoch 100]: val loss = 3.955185,   val acc = 0.472380,   val balanced acc = 0.519788
2025-06-08 22:22:19.393 | INFO     | model:train:258 - EarlyStopping counter: 2 out of 3
2025-06-08 22:22:28.999 | INFO     | model:train:237 - [epoch 101]: epoch loss = 0.213613,   acc = 0.967283
2025-06-08 22:22:38.709 | INFO     | model:train:237 - [epoch 102]: epoch loss = 0.211254,   acc = 0.967598
2025-06-08 22:22:48.242 | INFO     | model:train:237 - [epoch 103]: epoch loss = 0.213340,   acc = 0.967794
2025-06-08 22:22:57.754 | INFO     | model:train:237 - [epoch 104]: epoch loss = 0.214006,   acc = 0.967827
2025-06-08 22:23:07.441 | INFO     | model:train:237 - [epoch 105]: epoch loss = 0.210608,   acc = 0.967967
2025-06-08 22:23:17.291 | INFO     | model:train:237 - [epoch 106]: epoch loss = 0.207787,   acc = 0.968593
2025-06-08 22:23:27.137 | INFO     | model:train:237 - [epoch 107]: epoch loss = 0.208419,   acc = 0.968228
2025-06-08 22:23:36.778 | INFO     | model:train:237 - [epoch 108]: epoch loss = 0.207791,   acc = 0.968606
2025-06-08 22:23:46.718 | INFO     | model:train:237 - [epoch 109]: epoch loss = 0.203910,   acc = 0.969366
2025-06-08 22:23:56.616 | INFO     | model:train:237 - [epoch 110]: epoch loss = 0.204612,   acc = 0.968759
2025-06-08 22:24:06.361 | INFO     | model:train:237 - [epoch 111]: epoch loss = 0.206936,   acc = 0.968480
2025-06-08 22:24:16.165 | INFO     | model:train:237 - [epoch 112]: epoch loss = 0.203935,   acc = 0.969487
2025-06-08 22:24:25.919 | INFO     | model:train:237 - [epoch 113]: epoch loss = 0.202855,   acc = 0.969954
2025-06-08 22:24:35.728 | INFO     | model:train:237 - [epoch 114]: epoch loss = 0.200841,   acc = 0.970021
2025-06-08 22:24:45.667 | INFO     | model:train:237 - [epoch 115]: epoch loss = 0.198924,   acc = 0.969890
2025-06-08 22:24:56.030 | INFO     | model:train:237 - [epoch 116]: epoch loss = 0.199138,   acc = 0.969703
2025-06-08 22:25:05.932 | INFO     | model:train:237 - [epoch 117]: epoch loss = 0.198428,   acc = 0.969801
2025-06-08 22:25:15.653 | INFO     | model:train:237 - [epoch 118]: epoch loss = 0.200703,   acc = 0.970467
2025-06-08 22:25:25.597 | INFO     | model:train:237 - [epoch 119]: epoch loss = 0.197929,   acc = 0.970422
2025-06-08 22:25:35.553 | INFO     | model:train:237 - [epoch 120]: epoch loss = 0.197357,   acc = 0.970423
2025-06-08 22:25:35.995 | INFO     | model:train:245 - [epoch 120]: val loss = 3.940515,   val acc = 0.468146,   val balanced acc = 0.516836
2025-06-08 22:25:36.031 | INFO     | model:train:258 - EarlyStopping counter: 3 out of 3
2025-06-08 22:25:36.031 | INFO     | model:train:260 - Early stopping triggered.
